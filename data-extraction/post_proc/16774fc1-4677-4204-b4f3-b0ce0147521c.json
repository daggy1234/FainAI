{"data": [{"data": ["It's just going to be a lawyer. Look, if there is one thing that our families.", "L07: Parallel Algorithms Il", "Reference: Introduction to", "Algorithms by Cormen and all, 3rd", "edition, Chapter 27 (on Canvas)"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=0&isPrimary=false&absoluteTime=13351285501.015", "start_time": 1, "end_time": 9}, {"data": ["A few announcements when we get started. The first is that Homework two is due today, part of our weekly rhythm.", "It'll usually be on a Thursday. Unless it's a break week or an exam week.", "There won't be homework on those weeks. As always, we accept, at least for a few days through the weekend, a very minor penalty.", "You can see the details. The high level bit is if you need an extra day or two to finish it,", "please take an extra day or two to finish it and then please turn in what you have.", "By that time. Homework three is available on canvas.", "It's on parallel algorithms, which is also kind of, as you now know, about divide and conquer algorithms as well.", "So working with some similar concepts, there will be an applied problem for this week.", "It's in some ways kind of ironic that there is not an apply problem this week because parallel algorithms is an incredibly important practical issue.", "The reason that there's not an implied problem is because every language does it very, very differently.", "And also things run in a VM and it's complicated to know what courses you'll have access to,", "etc. And I don't want to spend the roughly extra week it would take to teach you how to use", "these concepts in the two or three or four particular languages of your preference in choice.", "So there won't be a required applied problem. But these concepts of divide and conquer parallelism can be applied in most modern languages.", "And if it's something that's interesting to you,", "I would absolutely recommend that you try playing around with it on your own device in your own language, and I'm happy to chat with you about that.", "Also show you an example here in a moment of implementing that in Python homework.", "I.", "Announcements", "Homework 2 due today, Thursday 2/1", "\u2022 Accepted late for up to 72 hours at very minor penalty,", "see the policy."], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=81&isPrimary=true&absoluteTime=13351285581.515", "start_time": 81, "end_time": 180}, {"data": ["Last time we had an introduction to parallel algorithm design and analysis,", "especially focusing on divide and conquer algorithms and how we can parallelize those in a spine sink or fork,", "join people, use those and honestly, style of multi-threaded parallelism.", "We had to talk a little bit about our abstract model of computation that we were going to use and how to reason about parallel speed ups.", "We defined the two crucial quantities for analysis, the work and the span,", "and we looked through a few examples of how you could design divide and conquer algorithms to take advantage of parallelism.", "We'll continue that today.", "I'd like to make a couple of kind of practical remarks to begin with and then to introduce you to something called a deterministic race,", "which is the number one possible new source of incorrectness that could be introduced when designing a parallel algorithm.", "The new kind of error for us to be worried about.", "And then we'll spend much of our time talking about how to solve the matrix multiplication problem with an extremely high degree of parallelism.", "You'll recall that we opened last class motivational speaking with the matrix multiplication problem as being one of the", "prime examples of a challenging algorithmic problem that we actually want to solve at very large scale in practice,", "especially in modern machine learning applications. That's what we're going to do.", "Outline", "Last Time", "Today...", "\u2022 Some Language Remarks", "\u2022 Determinancy Races", "\u2022 Parallel Matrix Multiplication"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=228&isPrimary=true&absoluteTime=13351285728.515", "start_time": 228, "end_time": 312}, {"data": ["I want to show you what would this actually look like if you really implement it on some puny little device that has multiple cores,", "but not like an arbitrarily large number such as my device, which I think maybe has eight cores that can share memory.", "I'm not sure this is an M1 processor. Those of you are interested in architecture, If you tell me that, here's what it looks like.", "I'm going to sort to to the 20 elements with this parallel divide and conquer algorithm.", "What I'm going to do is once I reach a certain size of input, I'm going to stop the parallelism and just run it in serial after that.", "So just run a normal. Ms. or after that. Okay. You can think of this as being sort of like a base case.", "It's not a base case.", "When I'm finished solving the problem, it's a base case when I'm going to stop doing things in parallel and I'm looking at changing that value.", "So at the right extreme of this plot over here, around 20, that is to say, once we get two to the 20, we're going to solve in serial.", "Well, the input was only two to the 20, so that's just the runtime. And if I ran regular merge sort, right.", "About 100 milliseconds on this input. Okay.", "Now, if I say let me run it in parallel until I get to an input of size two to the 90.", "Okay, So I'm going to run that. Basically, I'm going to split my input into two halves.", "Run both of those in parallel. Do everything below that in Serial.", "Okay. Then I cut the runtime almost exactly in half.", "Which recall is kind of the best you can hope for is a kind of a linear trend in its speed,", "obviously, because I'm only using two cores to do this right,", "because I'm just splitting the input into running those two parallel, doing everything after that serial.", "I'm getting roughly a linear speed up at that point. Okay.", "Then when I go down to solving a serial at a size to the 18, this basically corresponds to I'm going to use four course,", "I'm going to break my input into four chunks, sort all of those in parallel do.", "And then each of that, everything below that's gonna be done in Serial. And again, I see a really substantial speedup, but not quite as substantial.", "It's slowing down a little bit. I see. Maybe a little bit more speed up from going beyond that to using more force.", "But you'll see that after that, basically it makes no difference.", "This makes me strongly suspect that this is in Java for reasons I'll comment on in a moment.", "Okay. Why is it no difference after that? Because my device only has a very small number of processor.", "Course not one, but a small number, maybe eight or something like this that it's confusing.", "Okay. So what you'll see basically is if you've only got a small constant or processor pause, you won't be able to get an enormous asymptotic speedup.", "But on the other hand, it is a substantial speedup, right, from like 100 down to a little over 20.", "When to Stop Parallel", "Computation: Empirical", "AVG TIME TO SORT 2020 ELEMENTS WITH 8 CORES", "120", "100", "No benefit to more", "parallelism at this point", "with only a few cores", "Serial", "runtime", "0 2 4 6 8 10 12 14 16 18 20 22", "x where Cases Of size 2AX or smaller are solved in serial"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=2&isPrimary=false&absoluteTime=13351285860.515", "start_time": 360, "end_time": 540}, {"data": ["Ah, okay. Yes, it was. There we go.", "The previous data was running in Java that I got that Java supports parallel computation in multiple threads with access to shared memory,", "as do many other languages, including Golang, C++ and others.", "Okay, some of you may enjoy the Python programing language.", "In fact, I know that many of you enjoy the Python programing language because you choose to use that for the API problems in this class.", "Python's relationship with multithreaded parallel algorithms is complicated.", "Let me show you what I mean by that and then talk a little bit about it.", "Okay. We're going to talk about matrix multiplication.", "So here's some code that does matrix multiplication.", "In parallel, the details need not distract us.", "I have some code. This is a serial matrix multiplication and above that I have some stuff that does parallel matrix multiplication using in python,", "the multi processing. Okay. Don't need to know those details.", "That's just what's going on. But. I'm going to run a benchmark thing.", "I'm going to create to invite in matrices where I can set the value.", "Then they'll just have random values and then I'm going to time how long it takes to run in serial that matrix multiplication as well as how", "long it takes to run in parallel that multi matrix multiplication where I'm scaling up the number of parallel processes I'm creating actually.", "Okay. In order to do this in parallel. Let's start with a small ish size matrix of 59.", "So 250 by 50 matrices, meaning that they each have 50 square number of entries in total.", "Let's see what happens. So when I read this in Serial to do, the major simplification took less than a small fraction of a second 0.0 1 seconds.", "Actually, when I split into two processes to run on two separate cores, it took longer.", "Even just using splitting into two took like six times longer.", "And you'll see that this picture kind of gets worse.", "Programming Language Remarks", "Previous slide data was in Java, which supports parallel", "computation in multiple threads (along with Go, C++,"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=576&isPrimary=true&absoluteTime=13351286076.515", "start_time": 576, "end_time": 720}, {"data": ["So someone try parallelism in Python before I suspect it has run into these roadblocks.", "Python does support dynamic multithreading but with a big but.", "And the big problem is that only because of something that's called the global interpreter lock,", "only one thread is actually allowed to execute at any one time.", "So if your goal was to spin up eight threads and have them all doing work at the same time,", "sorry, the standard implementation of Python won't allow this.", "It will only allow one thread to execute on any given time in the python interpreter.", "If you still want to achieve parallelism where you actually have multiple operations happening in logical concurrency,", "you actually have to use multiple processes.", "And this is a deviation from what I said would be our abstract model of computation earlier, where you'll recall I said for our multithreaded model,", "we're assuming that a thread can be set up in constant time and B multiple threads have access to shared memory.", "Neither of those two things are true when you're using multiple processes in Python.", "When you spawn a new process, all of the memory from the old process has to be copied and there's no shared memory between the processes.", "What that means is that every time you spawn these new processes,", "it's actually a fairly large amount of overhead that has to happen and they can't access shared memory.", "If you need them to coordinate in some way, they have to actually like pause and send a message to the other one and wait to get that message.", "So that's just some information about Python.", "You can still use parallelism, but with the caveats that I mentioned before,", "essentially being that there is substantial overhead to it compared to our abstract", "model of multithreaded parallelism with constant setup and shared memory.", "Many other languages do support that model. For example, as I mentioned, Java, C++, Golang.", "Many others support that other model.", "I went into this whole aside just to say, Hey, things are complicated in the real world, but these actually do pose a question to you.", "This might seem like a very strange design choice about the Python programing language,", "but it is not because the language designers were lazy, nor because they hate parallelism, nor any of those reasons.", "There is actually a reason why the bacon programing language institutes this particular rule.", "They are worried about something. The language designer.", "And the thing that they are worried about is multiple threads operating concurrently with access to shared memory.", "Because multiple threads executing in parallel with access to shared memory cause errors, a new kind of error,", "a new kind of error that is particularly notorious and insidious and difficult to detect and correct, they cause something called deterministic races.", "So let's talk a little bit about that form of an error when you're talking about parallel algorithm design.", "Programming Language Remarks", "Previous slide data was in Java, which supports parallel", "computation in multiple threads (along with Go, C++,", "Python is...complicated.", "Live code demo"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=5&isPrimary=false&absoluteTime=13351286400.515", "start_time": 900, "end_time": 1080}, {"data": ["Suppose you have an array and you would like to sum all of the values in the array.", "You'd like to get the total of all of the values in the array that you would normally do this by writing some variable,", "some accumulating variable, looping over the array and adding each of the values one at a time to that variable.", "Or if you prefer programing languages with higher levels of abstraction,", "you would happily call it some function, which would then do precisely the loop I just described.", "If you wanted to parallelize that algorithm and if you were thinking in a divide and conquer fashion,", "then what you would probably do is say, Well, let me compute the sum in a divide and conquer way.", "Calculate the sum of the left half the sum of the right half. Add those two quantities together.", "And if I want to achieve parallelism to compute the sum more efficiently for a large array using multiple processor force,", "let me do those two recursive calls in parallel as we've discussed.", "You might write them a procedure, write an algorithm a lot like this where you want to sum all the elements in this array.", "You realize that your two recursive calls on line seven and eight can be computed in parallel.", "The order doesn't matter whether you add the values from the left hat first or the right half first doesn't matter, because addition is computers.", "So you say, This looks good to me. I'm finished with my parallel, highly efficient implementation.", "This algorithm actually has a bug, a very bad kind of a bug, what's called a deterministic race condition.", "Okay. A deterministic race condition.", "And it's happening on line seven and eight.", "So let's zoom in there online, kind of seven through eight there and see what I mean by a deterministic race condition.", "1:", "2:", "3:", "4:", "5:", "6:", "8:", "9:", "10:", "Parallel Sum the WRONG Way", "procedure PSUM(A, l, r)", "if I = r then", "return A[r]", "else", "spawn s = s + PSUM(A, l, m)", "sync", "return s"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=1083&isPrimary=true&absoluteTime=13351286583.515", "start_time": 1083, "end_time": 1188}, {"data": ["We have to actually add these values back into the variable. Yes.", "Okay. That could happen in either order because line seven and eight are happening in parallel.", "Suppose that we start in that left thread looking at the left side.", "What has to happen to execute S equals s plus PSM?", "Well, first you have to read the current value of S, which is zero at this point in time.", "Then you have to write the value s plus two s.", "Those are the two things that have to happen. But because these two threads are operating in parallel, what if we read s in the thread one.", "But before we write anything, thread two reads s s is still zero.", "Perhaps next thread one writes the updated value to s, which is ten zero plus the value of the recursive call on the left.", "And perhaps after that threat to write to s, we want it to write ten plus 20 equals 30,", "but it read a stable value of s when the red to read the value variable as it was still zero.", "It has the old value, so when it writes it will write zero plus the value is calculated from the right recursive call is 20.", "And when we get to the same statement to return s will actually be 20, not 30.", "This is called a Terminal C race condition because it is actually not deterministic.", "What the value of S will be at the end of the execution of this algorithm.", "This is the particularly insidious thing. If you run this program on this input, you will sometimes get the correct answer of 30.", "Other times you will get the incorrect answer of 20, and other times you will get the incorrect answer of ten.", "You can run the same program multiple times. You will get different answers depending on the order in which the different threads execute statements.", "You might run it ten times and get the correct answer every single one of those ten times,", "because this particular series of operations didn't happen in that order.", "Then the 11th time your program crashes, this is why the Terminal C races are such notorious styles of bugs and errors", "in algorithms because they can be very difficult to detect just by testing.", "And also very difficult to track down and debug. If we think a little bit more abstractly about what caused this deterministic race,", "Possible Parallel Execution", "6:", "7:", "2", "spawn s s + PSUM(A, l, m)", "s s + PSuM(A, m 1, r)", "Happening in thread I", "on core 1", "Get PMAX(A, m).", "say It's 10.", "7", "(line 6)", "3", "18", "Happening in thread 2", "on core 2", "cet 1, r).", "say it's 20."], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=7&isPrimary=false&absoluteTime=13351286760.515", "start_time": 1260, "end_time": 1425}, {"data": ["meaning that when I say logically parallel, I mean we think about them happening in parallel.", "What that really means is either of them could come before the other.", "We don't know which will happen first.", "When you have two or more logically parallel instructions reading from the same memory and one or more writing to that memory,", "whatever those two things are happening at the same time. The example I just mentioned before could happen to you.", "Okay, we call that a democracy race. I like to think intuitively I find it helpful to just remember two terms.", "Race basically happens whenever stale values are used for computation, which can result in incorrect output.", "Right. I said it again. I put it in a red box here that these are extremely pernicious errors.", "This is an algorithm that isn't incorrect. All. The time on the same test, but it's sometimes correct and sometimes not.", "Who knows? They're notorious in practice.", "They've caused famous errors in computer science.", "One of the most famous is in 2003. And you heard about the North American blackout.", "If you've heard of it before, you know what happened. No.", "Okay. So the the details of this. It was a large blackout.", "I mean, that's what happened. But the details.", "So power was lost in the electrical grid over several states of the American Northeast, like all of New York State.", "All of New Jersey State and so on, so forth, as well as several provinces of Canada, including most of Ontario, etc.", "Now, the cause of the blackout was an electrical failure in some complex electrical system that I don't understand.", "So you all are electrical engineers and that's your province.", "But there was a computer monitoring system put into place that was supposed to detect the onset of such errors and trigger an alarm,", "a series of more important alarms if actions needed to be taken within the electrical network to maintain stability.", "Such systems are commonplace and in practice Today, the alarm system had a determined AC race and the alarm never triggered because a deadlock", "situation arose in the way the software tried to handle possible determined AC races.", "So no automated alarm was raised for this event.", "That's just one example. There are other very famous examples of crashes caused by determined AC races.", "Let me show you what a correct way to have done parallel.", "Some would have looked like with the reminder that the whole reason we're talking about divide and conquer", "in the context of parallelism is because we think in divide and conquer about independence problems.", "Determinacy Race Defined", "A determinacy race occurs when:", "I. Two or more logically parallel instructions read", "from the same memory, AND", "2. One or more write to that memory.", "Can lead to a non-deterministic error when a \"stale\"", "value is used for computation.", "These errors are extremely pernicious in practice. Program might run", "correctly one day and incorrectly the next!"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=8&isPrimary=false&absoluteTime=13351286940.515", "start_time": 1440, "end_time": 1620}, {"data": ["I'm just going to very briefly mentioned you may have heard of the concept of locks or something like this.", "So many parallel algorithms and many systems contexts and things.", "You'll see people that will employ locks on a shared memory to prevent the kinds of errors we just described.", "Okay. In general, locks are a way of handling this problem, but they make it very difficult to reason about the algorithms using the locks correctly.", "In fact, they are notoriously difficult to reason about correctly.", "And they also introduce new problems that you have to be very careful to avoid", "deadlock where multiple threads are waiting on one another to release something.", "The idea at high level and also it makes it difficult to do the efficiency analysis because", "your threads might sometimes like pause and have to wait before they continue execution.", "We're going to focus in our class on totally lock free parallelism.", "That is to say we're going to focus on algorithms that are correct purely because they only do in parallel independent sub problems", "that are totally correct and can be analyzed by rigorously for efficiency without useful reference to any sorts of locks.", "So that's going to be the focus we'll take in this class.", "Locks vs. Lockless"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=1716&isPrimary=true&absoluteTime=13351287216.515", "start_time": 1716, "end_time": 1797}, {"data": ["Yes. In the process, or what was the process of using more of it?", "The question is what's used more often in practice? I would say in practice you often see algorithms implemented with locks.", "I think because the person implementing the algorithm may not fully understand how to design a lifeless parallel divide and conquer algorithm.", "I see that fairly commonly in practice. In other contexts, it might be necessary for your purpose.", "Some of those might be io io bound instead of computation or CPU bound.", "You might, for example, simply have a combined database that you want multiple things to be writing to,", "specifically just to keep up to date information or something like that.", "But it's not a CPU efficiency task. A couple of thoughts about it.", "Yeah, it's a wonderful place.", "It's like. It's like determinant. Is it determined or not?", "It's the sense that you might get different outputs if you run the same program on the same input multiple times.", "And it's in that sense non deterministic. But that's the origin again, multi.", "Parallel Matrix", "Multiplication"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=10&isPrimary=false&absoluteTime=13351287300.515", "start_time": 1800, "end_time": 1884}, {"data": ["and then your summing over all of those entries of the product of the two elements, I'll call this the inner product.", "Note that I'm following the standard convention in mathematics of one indexing here in the program I showed you before earlier.", "Of course I'm zero indexing in Python, but just a note about that convention I'm following.", "So here's what that looks like for a particular matrix A and B computing their matrix product.", "By the way, your ability to compute matrix products is not what is at stake here, and you will not have an exam question of the form.", "Compute this matrix product. We're interested in algorithms that do this for us.", "I'm just defining the problem for you. So this is where a particular entry is coming from.", "The row one column, one entry of the result matrix is the inner product of the first row of A in the first column of the E,", "That inner product is take the first element of the first row of A and the first element of first column of B.", "Multiply those together, add it to the second element of the first row of A in the second element of the first column of these things.", "Add those together and this is how we get our results.", "But computing a bunch of linear functions at once, essentially taking a lot of weighted averages,", "which is something that most deep neural networks do a lot of.", "Matrix Multiplication Problem", "The product of two n by n matrices A and B", "(21 43) 1", "is an n by n matrix C where Cij is the inner product", "of row i in A and column j in B.", "C = AB where Cij \u2014", "n", "aik"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=11&isPrimary=false&absoluteTime=13351287480.515", "start_time": 1980, "end_time": 2070}, {"data": ["Before we talk about how we would design a parallel algorithm for this. Right.", "Iterative Matrix Multiplication by", "Definition", "C = AB where Cij =", "Note:", "I-indexing", "aik", "k=l", "1: procedure MMULTIPLY(A, B, n)", "2:", "3:", "4:", "5:", "6:", "8:", "C = new n by n matrix", "for i = 1 to n do", "for j 1 to n do", "for k 1 to n do", "c.ij = Cij -F aik \u2022 bkj", "return C", "Runtime", "O(nA3)"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=12&isPrimary=false&absoluteTime=13351287660.515", "start_time": 2160, "end_time": 2172}, {"data": ["This is also I'm following our our reference text for this week of the concept of a parallel for loop.", "I will call the order beginning that spawn in sync or synonyms like for Conjoin are available in very,", "very, very many languages that support parallelism.", "The primitive of the parallel for loop is not necessarily okay, and I'll come back to that in a moment,", "but it will simplify our writing for clearly describing an algorithm, which is what I'm most interested in.", "I'll use a parallel for loop to indicate a loop where each iteration of that loop can be computed in parallel.", "Parallel \"for loop\""], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=2307&isPrimary=true&absoluteTime=13351287807.515", "start_time": 2307, "end_time": 2340}, {"data": ["As I said before, this is just a convenience for us when describing an algorithm.", "Unless you have specialized hardware known as like a vector processing machine or other things,", "typically hardware doesn't actually support a native parallel for loop like this.", "And the way that you would actually implement this with available language support would be by recursive spawning, as we've discussed before.", "That is to say really what we're going to describe more simply with this parallel for loop when we implemented algorithm more like this.", "Okay, so you should think like the the fork joint style of parallelism is the more general way of describing these algorithms.", "And this is a convenient shorthand for us, the way that you would actually schedule such a parallel for loop on a device without specialized support", "is by scheduling the first half of the iterations and scheduling the second half of the iterations,", "and then continuing to do that recursively to spin up the appropriate threads sort of in an exponentially fast way.", "Okay. That would be how you would in implementing that. And for that reason, when you think about the work and span analysis of a parallel for loop.", "How Parallel \"for loop\" Could be", "Implemented", "parallel for is just a convenience for us writing", "pseudocode. Without specialized hardware, it would", "be implemented by recursive spawning."], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=2415&isPrimary=true&absoluteTime=13351287915.515", "start_time": 2415, "end_time": 2484}, {"data": ["Plus the maximum span of any given iteration.", "This is under the assumption, as I said before,", "that the way that a parallel group has to actually be implemented is by recursively spawning the threads that run each iteration,", "which will have logarithmic overhead. It will take log in time to schedule a thread for each of the iterations just to spawn them.", "Okay.", "Unless you have some sort of specialized hardware where you can click a button in constant time and have scheduled a nine constant number of threads,", "none of your devices are generally capable of doing that.", "So, but it's added here, right? This is the overhead to schedule them and then it's the maximum span of any given iteration after that.", "So in the case where you have a parallel for loop like this, where the span of each iteration is only constant,", "you'll still have logarithmic span in this case where the dominating term is just the time it takes to schedule all of the threads.", "If you had arbitrarily many processors. Okay.", "Questions about the parallel for loop construct. Yes.", "And. Secondly.", "He said on returning to the square.", "What's. In your post. What does that mean in total?", "Right. So that so my point was that the whole inner for loop will execute and times excuse me in square times", "the whole algorithm and squared executions of the inner for loop which had linear time or a cube,", "but the inner loop itself will execute quadratic thing many times and we will return to that algorithm in a moment that you're crazy.", "Yes, they were all from 1 to 10. Yeah. Yes.", "How do you know that? All the scheduling happens in one process.", "Say more about that question. So this is the maximum amount for better policy.", "That's right. And by the way, you're assuming you have arbitrarily many course when analyzing spam.", "Right. But then over here is that people were skeptical of the iteration where assuming that", "is possible for one officer to take on the overhead of scheduling all the iterations.", "No, this is actually done recursively in the multiple course. Right.", "If that's the case, that there is no one possibly that has all the configurations.", "And if that's the case, then why? Why? So the question is, why is it so?", "Although, again. You start with in iterations to schedule on one thread.", "You split that up. Now you've got two threads each within over two iterations of schedule.", "Work and Span of Parallel for loop", "All l. procedure INCREMENTALL(A, n)", "2:", "3:", "parallel for i = O to n \u2014 I do", "end parallel for", "Tl(n) =", "Work at iteration i", "Tl (n) = (n iterations) \u2022 (O (I)work per iteration)", "Tl(n) is O (n)", "Too(n) = O(log(n)) + max(Span of iteration i)"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=14&isPrimary=false&absoluteTime=13351288020.515", "start_time": 2520, "end_time": 2700}, {"data": ["I've introduced the idea of the parallel for loop.", "I have to warn you, it is very easy to accidentally introduce a deterministic race with a parallel for loop.", "I introduced the spine in sync primitives first,", "because the primary way you think about a parallel algorithm is by designing divide and conquer algorithm with independent sub problems.", "And because it's a more general primitive, this is a convenient shorthand, but it is very easy to write deterministic races with parallel for loops.", "Here's an example that looks very innocuous. I want to sum all the values in an array.", "Do a parallel for loop and out each of those values in logical parallel.", "But of course, the problem is you're using one accumulating variable s,", "and potentially all of those threads are going to end up trying to read and write from s in logical parallel.", "And it is entirely plausible that this will result in an incorrect output.", "So you have been warned. It is very easy to write these things.", "If we come back to our parallel matrix multiplication problem, though,", "remember our earlier intuition was that we can do each of the in squared outer iterations of the inner for loop.", "That is to say, you know, we're going to get to line five in squared times right because of the two outer", "for loops and we can do each of these in parallel because they only write two CIJ.", "We can indicate that with two outer parallel, four loops, basically saying compute each entry of C in parallel,", "but for each entry online, six and seven calculate that particular entry's value in serial.", "Warning: Very easy to introduce a determinacy", "race in a parallel for loop by accident", "This looks like it calculates the sum of all elements in", "the array in parallel...", "1:. procedure", "6:", "parallel foi\u2022 i = O to do", "end parallel for", "return s", "But if each iteration runs in parallel, then multiple", "threads are writing to s at once."], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=2781&isPrimary=true&absoluteTime=13351288281.515", "start_time": 2781, "end_time": 2880}, {"data": ["Let's analyze this for a second. And you said you've got n squared parallel iterations, right?", "And squared iterations that can, if you've got in squared process, of course can all happen in parallel.", "Each one of them thinking about the work analysis first does a linear amount", "of serial work on the inner loop starting on line six per parallel iteration.", "So we get a total of in cubed work, which again, maybe it shouldn't surprise you that that's equal to the work from the serial algorithm.", "However, the span now it'll take us log in time to schedule all of those outer parallel four loops earlier.", "That was what dominated the span.", "That will not be the case here because now, even after you've scheduled all of those outer for loops and log in time,", "you actually have to compute the interlude in serial on every particular thread, which will take you linear time to run the inner for loop online.", "Six Is that the maximum span of any of the parallel iterations will be equal to well,", "they're all going to be linear, the span and each particular parallel iteration.", "And so the span will be dominated by the work that has to be done after the scheduling, so to speak, linear.", "In this case, the implication being if you were to multiply two end by and matrices,", "if you have arbitrarily many processor cores, you can use this algorithm to compute that product in linear time.", "With respect to one dimension of the matrix, which is pretty impressive. These are the questions about how I got this analysis.", "Yes. So what you have just been up and squared for this, So would it be longer than squared?", "Yes. And we're still going. Yeah. Which is a good identity for everyone to remember.", "Right. That from rules of logarithm. So log of n squared is equal to two log in.", "Yeah. So I need the bigger. Yeah. Now, the question you should be asking yourself because you're a curious person, could we be linear span?", "Could we actually, if we had even more processor course, could we take advantage of even more massive parallelism?", "Analysis of Parallel", "Matrix Multiplication", "2:", "87", "procedure", "C = new by matrix", "parallel for i to do", "parallel for I to n do", "fork I ton do", "= e_ij \u2022", "end parallel for", "end parallel for", "return C", "10;", "(n2 parallel iterations)", "x (O (n) serial work per parallel iteration)"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=2910&isPrimary=true&absoluteTime=13351288410.515", "start_time": 2910, "end_time": 3060}, {"data": ["We'll come back to this question after a break.", "But it wasn't the most.", "Very nice. I was thinking about what comes to mind.", "I be. We had a conversation with one.", "It might seem like it was something that was going to happen.", "Yeah. We were standing right here.", "Each client is going to crack each other.", "You know, I got a chance to show you how it's going to be.", "I feel like I say thank you so much for having me.", "You know, I was like, Oh, yeah, You know, And I mean,", "like like I said to myself that I like the fact that walking out on my sister in high school, I was I doing.", "Yeah. Yeah, I really do.", "In-Class Exercise", "duke.is/i/xxim", "Talk with your neighbors,", "Submit on your own.", "Graded for completion,", "not correctness.", "1"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=3066&isPrimary=true&absoluteTime=13351288566.515", "start_time": 3066, "end_time": 3240}, {"data": ["I want to remind you that you is.", "You know, I'm really like.", "Sounds like a working man.", "Yeah. Yeah. I was like. I think what you're saying is not totally.", "Absolutely. Just one more minute.", "Try to give us your best guess if you haven't yet, for a lot of reasons.", "And now I want to tell you how.", "Yeah. Oh yeah, that's right.", "That's. Three years now.", "They're still trying.", "Right now, you guys.", "Yes. Yes, I know.", "I, I may have become law enforcement to disagree with it.", "I did not know how long it is going to.", "In-Class Exercise", "duke.is/i/xxjm", "Talk with your neighbors,", "Submit on your own.", "Graded for completion,", "not correctness.", "1"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=19&isPrimary=false&absoluteTime=13351288920.515", "start_time": 3420, "end_time": 3600}, {"data": ["First question, does this create a deterministic race or do people think the correct answer is no?", "It does not create a deterministic race for the first problem.", "The reason is note that B is only ever being read from writing to B, we're only ever reading the values.", "So B is not a concern.", "A is the concern because we are writing values to A But note that only the iteration reads from or writes to A.I and not to anything else.", "So this does not exhibit a deterministic race.", "Only one thread is reading and writing to the memory position.", "I for any second question, does this create a deterministic race?", "Slightly different looking problem. The correct answer is indeed.", "Yes, this does create a determined C race.", "Does this \u2022", "2:", "3:", "4:", "parallel for i 0 to n \u2014 1 do", "end parallel for"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=3666&isPrimary=true&absoluteTime=13351289166.515", "start_time": 3666, "end_time": 3738}, {"data": ["We got a problem. Maybe, or maybe you'll run it. It'll be correct.", "It's hard to tell the term to see reasons. For the third question Does this cause a determine a series?", "We're a little split. Correct answer is yes, it does.", "I think I remember the question correctly.", "L07 in.aass Exercise (2/1/2024) \u2022", "Questions i", "Does this create a determinacy race? \u2022", "6:", "8:", "parallel for i 0 to n \u2014 1 do", "Ali] = Ali] + + 1]", "end parallel for", "O Yes (causes d race)"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=21&isPrimary=false&absoluteTime=13351289280.515", "start_time": 3780, "end_time": 3804}, {"data": ["So rather than two tier then over two we just have to get over to analyzing the spam.", "Then for the parallel for loop down below, we've already discussed how the span of that parallel for loop will be logarithmic, right?", "So the overall recurrence you would get to characterize the, the span of this algorithm would be t of t sub infinity if you want to write it that way.", "Is this of affinity in over two plus of log in, solve that in whatever way best suits you,", "you'll find the solution is log squared event which is still by the way really good I", "mean log in log squared event and still exponentially better than linear in this case.", "Okay, So well done overall. Thank you, everyone.", "Questions i", "L07 ln.aag Exercise (2/1/2024) \u2022", "Let The Of the WOW procedure is\u201e. \u2022", "Select your answer", "procedure wow(A, l, r)", "if I = r then", "else", "m = + r)/2J", "spawn wow(A, l, m)", "y = + l,r)", "parallel for i I to r do", "Ali)", "end parallel for"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=22&isPrimary=false&absoluteTime=13351289460.515", "start_time": 3960, "end_time": 4014}, {"data": ["Like me. Divide and conquer some max. ET cetera. Have a kind of similar form.", "In our base case. We simply return the product of two particular elements at the corresponding positions.", "Otherwise, we're going to split into computing the inner product of the left,", "half of the either of a in the left elements of the J of column B and the right, if you will.", "We'll sink and then return. The sum of those to the work of this algorithm will make two recursive calls each on an input of half the size,", "and then we do a constant amount of work in the combined step just to add together the two results which will result in linear work,", "which is the same as we had from just a simple iterative loop.", "The span. However, now a single thread only needs to handle one of these two recursive calls on an", "input of half the size plus the constant amount of extra work in the combined step.", "The span will come out to be logarithmic in the number of elements.", "Right? This is a common trick. This is what we're going to be doing with the design parallel algorithms.", "Often if one or two higher degrees of parallel ization,", "you'll use the obvious divide and conquer algorithm or the not so obvious divide and conquer algorithm,", "or the larger problem of interest parallels the recursive calls.", "If you want to achieve a higher level, think about how you can design a parallel divide and conquer algorithm for the combined stack.", "That would be a typical trick. We can plug that into our parallel matrix multiplication algorithm.", "Parallel Divide and Conquer Inner", "Product Helper", "Return the inner product Of indices I through r Of row i Of A", "and column j of B.", "1: procedure PINNERPRODUCT(A, B, i, j, I, r)", "2:", "3:", "4:", "5:", "6:", "8:", "9:", "if I = r then", "return blj", "else", "spawn = PINNERPRODUCT(A, B, i, j, I, m)", "y = PINNERPRODUCT(A, B, i, j, m + 1, r)", "sync", "return Y"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=23&isPrimary=false&absoluteTime=13351289640.515", "start_time": 4140, "end_time": 4233}, {"data": ["It can use as many cores as you can throw at it is the intuition you should have,", "which is why massively parallel architectures are very, very, very good at computing matrix products.", "Analysis of Parallel Matrix", "Multiplication (again)", "I: procedure PMMULTIPLY(A, B, n)", "2:", "3:", "4:", "C = new n by n matrix", "parallel for i = I to n do", "parallel for j = 1 to n do", "Cij = PINNERPRODUCT(A, B, i, j, O, n \u2014 1)", "end parallel for", "Tl(n) na (TIP Innerproduct(n))", "end parallel for", "Work is O(n3).", "return C", "Span is"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=b14e4888-5c2e-4d07-b3fd-b1090146c261&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=24&isPrimary=false&absoluteTime=13351289820.515", "start_time": 4320, "end_time": 4335}, {"data": ["But I'll leave it for those of you who are curious, the basic idea in brief is when thinking about elements,", "think about taking your matrices and breaking them up into in by four and by four blocks, sub blocks of your matrices.", "It turns out that the resulting product of the two matrices can be written as many multiplications and additions of these blocks of matrices,", "Matrix Multiplication Revisited", "The product of two n by n matrices A and B, broken", "up into 4 n/4 blocks"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=4422&isPrimary=true&absoluteTime=13351289922.515", "start_time": 4422, "end_time": 4452}, {"data": ["But this guy named Strawson at this very clever observation and I don't know what I was going to say.", "Strassen's Clever (if tedious)", "Observation", "(Alibii + A12B21 AllB12 + A12B22", "+A22B21 +A22B22"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=4488&isPrimary=true&absoluteTime=13351289988.515", "start_time": 4488, "end_time": 4500}, {"data": ["You go to the unifying method, you calculate the runtime.", "It's not cubic. Isn't that obvious?", "This is in the 2.8. I know. I know what you're thinking.", "2.83. Who cares? 2.83 is in the in the polynomial.", "The degree of the polynomial. We are not talking about this. Making the algorithm 10% faster if you're multiplying.", "Really, really, really big matrices. This is crazy faster to use than the naive cubic algorithm.", "And hey, by the way, you can highly parallelize this as well, bringing down both your work and your span fun bonus rule material.", "I hope you all thought this is interesting. Please take care. Enjoy the rest of your day.", "So I think we have to stand up.", "Guess. We are.", "But I. I heard.", "We have.", "Well, you know, I think the party has to actually take one of their answers that it needs to capitalize on it having handled one of these policies.", "And then there's the question of why this party?", "I love the smell of your eucalyptus is always log in to schedule.", "The animation takes a long time.", "Plus the span of any given maximum span of any given year, you should know that's constant, but it'll still take you like an hour sketching out.", "And you might have to make all of the sketch compress over scheduling, scheduling, sketch.", "We see it as you do.", "Strassen's Algorithm Runtime", "Analysis", "From 8 recursive multinucations to 7.", "From 4 to 18.", "T(n) +0012)"], "image": "https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=079887c4-fed8-446e-bd11-b1090146e1fe&sessionPID=64055e1a-5964-4c6f-acb5-b0ce01475214&number=4521&isPrimary=true&absoluteTime=13351290021.515", "start_time": 4521, "end_time": 4680}]}