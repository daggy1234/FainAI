{"data":[{"start_time":1,"end_time":3,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=0&isPrimary=false&absoluteTime=13351112701.047","captions":["I. I."]},{"start_time":180,"end_time":219,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=1&isPrimary=false&absoluteTime=13351112880.547","captions":["problems in algorithms that are important even for large scale deployments in artificial intelligence today.","So stay tuned for more about that. As a reminder, the reference for this week, Ericsson does not include a discussion on parallel algorithms.","So the main or the primary reference for this week is chapter 27.","From introduction to algorithms by Foreman at all.","You can find a PDF of that chapter on canvas under I think it's under additional readings on files or something like that.","So you can find the reference there if you like to start as usual with some announcements."]},{"start_time":360,"end_time":378,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=2&isPrimary=false&absoluteTime=13351113060.547","captions":["For example, did you do the Java, the Python one and dropping the lowest problem like all of that stuff is going to","get pushed process afterward and then your final drag will go up on canvas later."]},{"start_time":540,"end_time":642,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=3&isPrimary=false&absoluteTime=13351113240.547","captions":["That would be rather pointless. But I think this is important to point out,","because too often when I talk to people about algorithm design or mathematics or whatever thing it might be,","that maybe I felt bad about this at one point in a previous class or a friend seems to know so much more about this than I do,","or I just don't know if I'm ever going to be able to do it.","It can be self-defeating and a self-fulfilling prophecy where someone says, You know what, I just can't do this.","I believe that all of you can do this. And I think that you believing that for yourself is the first step to being able to do it.","It's important to recognize that otherwise you will never find the motivation to sit","with a problem long enough to digest it and let your mind do the work to learn it.","As I said, I try to make the practice opportunities tightly coupled with your assessment,","that is to say with exams and so and to like so that you actually feel like you can prepare fairly for what you'll be assessed on later.","And so in the exams you I'm not saying my you will see problems from homework, from recitation, from lecture, from things you've seen before.","You will see them again. So I hope that's an incentive.","Not that you need to treat every individual homework as a take home exam.","It's going to be graded very generously for the practice part of the homework,","but that you take it seriously in terms of trying to understand it in the long run.","Any questions about announcements or. I apologize for my waxing poetic aside.","Okay, well, let's design some parallel algorithms now."]},{"start_time":699,"end_time":720,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=699&isPrimary=true&absoluteTime=13351113399.547","captions":["First, a cartoon of what I am even talking about when I talk about parallelism.","A cartoon. Envision yourself, you and a team of four of your colleagues have to sort an enormous stack of papers."]},{"start_time":900,"end_time":912,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=5&isPrimary=false&absoluteTime=13351113600.547","captions":["So this is a cartoon, but the workers you should think of as being processor cores on a modern computer."]},{"start_time":1050,"end_time":1080,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=1050&isPrimary=true&absoluteTime=13351113750.547","captions":["Well, it turns out there's a very deep connection between algorithms and these kinds of large models for how they work under the hood.","And the particular algorithm task of most interest with respect to efficiency is matrix multiplication of all things.","Many of you may have taken linear algebra or some other class and may be familiar.","It's all right if you're not familiar with the details of what a matrix multiplication is, I give you two matrices A and B,","The product of those two matrices is for every row in the first matrix and for every column in the second matrix."]},{"start_time":1260,"end_time":1323,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=7&isPrimary=false&absoluteTime=13351113960.547","captions":["Well, outside of theoretical or abstract algorithm design,","this is an important question in the real world is one of the ways that Nvidia is making a killing in","the market because they design hardware that is extremely efficient at computing large matrix products.","That hardware that they build is massively parallel.","Indeed, one of the distinguishing features of a typical GPU, a graphical processing unit or a tensor processing unit is that they are highly parallel.","So parallelism is at the heart of all of this.","We'll talk more about matrix multiplication next time.","Have that in the back of your head as maybe a motivating or an interesting application or connection.","I want to introduce you today to the basic model and the ways to think about the design of the analysis."]},{"start_time":1398,"end_time":1437,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=1398&isPrimary=true&absoluteTime=13351114098.547","captions":["That is actually an old view. It is not particularly accurate over your lifetimes.","The idea that a CPU, a single core operating in serial is getting much faster every year.","It's not like that stopped being true last year. Hasn't been true in most of your lifetime, actually.","Okay.","You were plotting a very a variety of different metrics of what's been happening in the development of new processors over the last 50 years or so.","And I'd like to zoom in on a few salient features within the last couple of decades,","in the 21st century in particular, each of these dots represents like a processor coming out onto the market."]},{"start_time":1440,"end_time":1587,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=8&isPrimary=false&absoluteTime=13351114140.547","captions":["The first observation is that the typical processor became multi-core, meaning capable of parallel algorithm execution,","capable of doing multiple things simultaneously, having multiple workers, so to speak.","The typical processor in the market became multicore between 2020 ten, and prior to that time,","most processors that were sold in most PCs had only a single core for most applications.","Today, almost all processors that are used are multi-core.","Your laptop is multicore. Almost certainly your phone is highly multi-core, almost certainly so on and so forth.","GPUs, as we were talking about their use for machine learning, are even a different story entirely.","Just looking at CPU use here, but they're all multi-core. Well, why why do people start all of a sudden designing multicore processors?","The clock speed the number of cycles per second or instructions per second that can be","handled by a typical individual core hasn't actually been increasing for about 20 years now.","If you look at the the green, the frequency, like if you buy a processor, it'll say the clock speed.","Like how many gigahertz does it have my desktop computer from when I was your age had more gigahertz than my current laptop does.","This hasn't really actually been increasing for about 20 years now in general.","So it is not true. And so single thread performance, that is to say,","just like the runtime of an algorithm in serial execution has been increasing slowly by tricks other than the clock speed, but only slowly.","Not the kind of trend that we saw with Moore's Law over the last few years.","So indeed, computer hardware has not been getting extremely much faster at running a program in serial execution over the last couple of decades.","Insofar as hardware has become more powerful, the dominating trend of that power has been a move to multi-core and parallelism.","But if you want to exploit that parallelism to actually get your algorithm to run faster, you need to think about parallel algorithm design."]},{"start_time":1620,"end_time":1752,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=9&isPrimary=false&absoluteTime=13351114320.547","captions":["Independent of anything else. When you launch a program, you're launching usually a process on your computer.","I will instead use the concept of a thread of execution.","A single process may have multiple threads of execution potentially scheduled on multiple cores,","which may execute in parallel, and the threads will share memory.","So in general, your algorithm will start a process. It has its own pool of memory.","You may launch multiple threads executing in parallel. They may be able to share memory between each other pictorially.","Our old view, our typical view of how an algorithm executes our kind of Turing machine view, if you will, is that we have a single processor world.","It has its own memory. It reads and writes that memory and executes instructions.","Very simple. And we typically analyze the number of constant time operations that that core has to perform.","In our abstract parallel multi-threaded model of computation.","We'll imagine that we have multiple processor force.","They have a shared memory that they can access so that they don't necessarily have to pass data back and forth between each other.","And they may also have their own local memory.","So they may have, for example, their own local variables in the same name or something like.","The question. Now, if you imagine an algorithm executing in this abstract parallel,","multi thread model of computation is what exactly will we analyze when we want","to think about the efficiency of an algorithm that is running in this way?","And are there questions about the abstract model of computation?","This week, we'll look at two fundamental quantities in our analysis."]},{"start_time":1800,"end_time":1980,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=10&isPrimary=false&absoluteTime=13351114500.547","captions":["We'll use asymptotic notation to characterize both the work and the span asymptotically.","The Spaniard, by contrast to the work, is the maximum number of constant time operations that will happen on any one four.","If you had arbitrarily many cores to use at the work therefore characterizes the total number of","operations summed up the span will characterize how long will it take for execution to complete.","If you had arbitrarily many cores to use because whichever core had the most work to do is the one that will take the longest.","Right? Let me show you a different way to think about this and then I'll take a question.","If this doesn't clarify things for people. Alternatively, if I write ts P of N to be the runtime of an algorithm on an input of size,","n so far so usual using P processor course, I'm parameterized by the number of processors I have available.","Presumably with more cause I can reduce this for a parallel algorithm.","Then the work of the algorithm is just t sub one of n or the serial work.","The serial run time. You want to analyze the work of an algorithm.","Just imagine that you only actually have one core. Nothing happens in parallel.","Remove anything having to do with parallelism from the algorithm description and ask how much?","What would be the runtime algorithm. By contrast, the span is the far extreme of this t sub infinity of the runtime.","If you had arbitrarily many cores that you could schedule the work on.","One thing you might think is that for any given, remember that these are properties of an algorithm, not a problem.","That's one thing to point out.","And as a second thing, it may be common to think if I have arbitrarily many cores, shouldn't I be able to perform any task in constant time?","But the answer is no, because remember our earlier cartoon, you've got to coordinate that work somehow.","You've got to combine, you've got to divide up the work. You've got to combine of the work in some consistent way.","So the answer will not be that everything can be solved with constant snap.","Indeed, very few things can be questions about the work in the span.","We will do examples later. That would be helpful.","Yes, if you get arbitrarily many processors and you just like parallel compute for several weeks twice again,","if you have a truth table isn't anything with the truth, then we'll be able to do problems.","Note how the question is Can't I just solve the truth table in constant time?","You were saying before, how will you set up the truth table in constant time?","If execution begins on one core. There is no way that you can now schedule arbitrarily many sub portions of that table to happen on your arbitrarily."]},{"start_time":2064,"end_time":2103,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=2064&isPrimary=true&absoluteTime=13351114764.547","captions":["Let me show you an example and we'll come back to our old favorite, calculating the maximum value out of an array.","We looked previously at this divide and conquer algorithm to solve this problem.","And as I said, divide and conquer is going to be our paradigmatic design technique for parallel algorithms.","How did this work? Well, we took our input array.","We split into two halves. Recursively calculating the maximum in both of the two halves, and then returned the greater of those two.","That was our divide and conquer algorithm. We already have our dividing combined step.","How do we introduce parallelism to this? Let me do it in pictures first."]},{"start_time":2160,"end_time":2223,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=12&isPrimary=false&absoluteTime=13351114860.547","captions":["And one of them maybe get scheduled under blue. One of them maybe get scheduled on the green for each of those.","We'll split it into two sub problems and schedule each of the sub problems to run in parallel potentially on different course.","So far, all we've been doing is dividing up the input and assigning them to different course.","At this point, we've hit base cases. Or maybe we don't have any more processor cores anyway.","We'll talk about that later as well. So suppose now we actually compute these base cases on each of these course.","We return the answers in parallel. We pop back, we have these two sub problems.","We do the merge step and we return the answers.","And now we have the original thing we started with and we return the overall answer in a picture.","This is what the idea looks like. A parallel execution of a divide and conquer algorithm."]},{"start_time":2340,"end_time":2376,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=13&isPrimary=false&absoluteTime=13351115040.547","captions":["to schedule as the other primitive design introduces the concept of a sync or synchronize,","which simply says, Wait here until any threads that you have spawned have completed execution.","So it just says pause until all of the threads that I've spawned have finished.","Typically we're going to spawn on one of our recursive calls in our divide and conquer algorithm, and then we're going to sync before the merge step."]},{"start_time":2451,"end_time":2511,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=2451&isPrimary=true&absoluteTime=13351115151.547","captions":["The short answer is it doesn't help.","Why doesn't it help Schedule line six to run in another threat as what we're saying and online seven scheduled this to also run in another thread.","Then the original thread, the original context that was executing this immediately hits a sink and stops and whittles its thumb with nothing to do.","Yeah. So this is legal.","Like this will work, but it doesn't actually yield any speedup over just the single spine.","On the first call we had previously. Because remember, there was a thread that was originally executing this in the first place.","So if you need two threads to make these two recursive calls, you only need one new one, right?"]},{"start_time":2520,"end_time":2700,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=14&isPrimary=false&absoluteTime=13351115220.547","captions":["What happens if we do this? We're saying, okay, do line six in the current thread.","We're in serial execution in this given thread, meaning it's going to do all of that recursive call before it goes on.","To look at line seven, we get to line seven and says, okay, now after I've already completed everything on line six, the first recursive call,","now schedule this in another thread and now immediately pause and the current thread again waits until that one finishes.","So this putting the spawn on the second call actually executes in serial and gives no parallel ization, no speedup whatsoever.","Okay, so typically if you have multiple recursive calls and in parallel divide and conquer algorithm,","you'll spawn on each of the first few recursive calls up until, but not including the last one.","That's typically what you'll see in the pseudocode.","Conceptually, what you should have in mind intuitively is I'm just saying I have two recursive calls.","Run those in parallel. But this is the way that will indicate that with our primitives.","Question Yes, it's responding recursive because what happens if you have an incorrect number that has,","for example, recursive actions and you're spotting a bunch of recursive calls?","And the question is about if you have an incorrect procedure algorithm, meaning incorrect even in serial execution.","Nothing new, but we're going to talk about later, right. All bets off.","If the if your algorithms incorrect and you're running in parallel execution,","it's not going to become correct in terms of what's resulted, what's resulting.","If the form of the incorrectness, where the error is that you're not approaching a base case or something, then the program might just crash.","As it would have in serial driving. Yes.","You wouldn't have to be more efficient. Continue to find a beyond the machine.","And you think that. If you spawn the if you find a while, you're waiting for your package as this process being been.","Yes, exactly. And that's what our first example, a good example did was fight on the first.","Precisely. Yes. That is the correct way to think about it. Yes.","You have to know in advance how many words you have. Immediate response oftentimes.","We'll talk about this in a moment. The question was, do you have to know how many cores you have?","The short answer is if indeed scheduling a thread is very small, constant overhead, basically no.","And you can just keep doing it until you get to a base case.","In practice, you'll want to terminate early, depending on how many cores you have and how much overhead there is to schedule.","One will typically abstract that.","So when we design an algorithm in theory, because in theory we have no idea how many,"]},{"start_time":2871,"end_time":2880,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=2871&isPrimary=true&absoluteTime=13351115571.547","captions":["First, looking at the recursion tree itself. Just drawing that again,"]},{"start_time":3024,"end_time":3060,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=3024&isPrimary=true&absoluteTime=13351115724.547","captions":["You can analyze this differently, and sometimes this is more convenient with a recurrence relation.","So for example, we could look at the algorithm itself and say, If I'm analyzing the work,","I'm just ignoring spawn in sync and ignoring the parallelism.","I'm just thinking about one processor for, I mean, two recursive calls each on input of half the size and pull of one additional work.","So I would get a recurrence of the form T of sub one of n is at most to excuse me,","I should say t sub one of and over two plus c a recurrence we have seen before","and we solution is again length as we discussed from the recursion tree."]},{"start_time":3117,"end_time":3240,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=3117&isPrimary=true&absoluteTime=13351115817.547","captions":["Let's talk to each other among yourselves and think for a moment about analyzing work and span.","Take a look at this and come back together in just a few minutes. Each of you.","Oh, I forgot all about that.","Yeah, I'm also taking some pictures. Yeah.","So this is a big ticket? Yeah, if you have a ticket.","She goes on the TFT operation environment tree function and is.","And it just seems like this is like a way of just more like a standard moment for others.","Yeah, because I feel like when I was like yesterday for the first time."]},{"start_time":3315,"end_time":3420,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=3315&isPrimary=true&absoluteTime=13351116015.547","captions":["And that is.","Speaker one Oh. Oh, yeah, yeah, yeah, yeah, yeah, yeah.","You're all right. Elections should be an option for all of them. So if.","If the answer is oh, then choose one at random. Provide. Oh, I think.","I have been around for a very long time.","And. Yes. Yeah."]},{"start_time":3600,"end_time":3780,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=20&isPrimary=false&absoluteTime=13351116300.547","captions":["I think I. I guess.","Never know.","I just can't go on.","I can't. I can't.","And I want you to do it for me. I really want to hear from you.","Sponsorship this. How do you see it?","I know what you are.","I guess you're right.","All right, let's take a look at these together. All right.","So I know it's is first question.","We've got two procedures here. Who in Bart's? The work of Barr will be What?","But what will the work of art be like? This is going to be a fun one."]},{"start_time":3954,"end_time":3960,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=3954&isPrimary=true&absoluteTime=13351116654.547","captions":["So what do we get mean to recursive calls, each on an input of half the size plus in the merge step we call bar in."]},{"start_time":4140,"end_time":4140,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=4140&isPrimary=true&absoluteTime=13351116840.547","captions":[]},{"start_time":4167,"end_time":4224,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=4167&isPrimary=true&absoluteTime=13351116867.547","captions":["I don't need to scroll that much.","Person who are analyzing through the merge step here makes a call to bar and the work that bar does on an input of size and is linear.","And so we get more work done for a merge step.","And that's what resulted in the difference between the work analysis between the two.","And it's the kinds of occurrences here are mirroring what we saw.","For example, for like the divide and conquer maximum algorithm is like bar.","And the Mercer recurrence is like food when analyzing the works.","Yes, yes, yes.","Yeah. Because you're thinking about just like the maximum work on any single path in the total recursion tree.","Yeah. Let me say a few things about reasoning about the parallel speed up with the minutes that we have remaining here."]},{"start_time":4230,"end_time":4305,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=4230&isPrimary=true&absoluteTime=13351116930.547","captions":["There are a couple of so-called laws you should be aware of relating the work and the span, these quantities that we've been discussing.","The work law is that the actual runtime with key processors is going to be processor","cores is going to be at least the work divided by the number of processors.","The reason just intuitively is that at least one core has to do at least one over p of the work.","If you have pea processor cores and you have some amount of work that needs to be done total,","at least one of those processor core has to do at least one over P at least the average amount of the work.","Some people call that the Pigeonhole principle. The span law, by contrast,","is that the actual empirical runtime with processor cores is going to be at least the","span that I hope is pretty intuitive because you do not have infinite processor cores.","You might have a lot, you do not have an infinite number. Okay, So you're never going to be able to do better than the span in terms of runtime."]},{"start_time":4320,"end_time":4383,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=2bc17a8f-560d-4807-82bf-b1070146cc33&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=24&isPrimary=false&absoluteTime=13351117020.547","captions":["this is what you would actually see empirically as the speed up factor using P cores for your algorithm.","If you combine the work and the span laws, you can get a bound on what you can expect for the speed up that in particular your","speed a factor can be at most P where P is the number of processor course you're using.","And for that reason you'll hear people talk about perfect linear speed up being the best you can","hope for is that the speed up factor is linear in the number of processor force you have to use.","That's the best you could hope for.","You might not always be able to achieve that with your algorithm design, but that's the best that you could hope for.","If you have perfect linear speed up, what it means is actually pretty intuitive.","If I give you twice as many processor cores, you can run the algorithm twice as fast.","Precisely what perfect linear speed up would mean. That's the best you could hope for."]},{"start_time":4470,"end_time":4500,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=4470&isPrimary=true&absoluteTime=13351117170.547","captions":["then as we mentioned before, you don't really need to parallelize all the way down to the base cases.","You can just divide up into fairly large chunks of sub problems and then run those in cereals.","For example, if you're running parallel merge work and you know you only have four cores to use for this,","you can just use an algorithm like this that says,","Hey, once I get down to like a fourth of the input, stop this parallel business and just run the regular serial merge."]},{"start_time":4575,"end_time":4680,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d5cf2f47-0905-42c7-9da7-b1070146e8be&sessionPID=a389df8c-087f-47be-9720-b0ce014751f9&number=4575&isPrimary=true&absoluteTime=13351117275.547","captions":["I can't tell you.","I want to ask you.","In principle, it would be great for any that we'll see later.","The problem is if you're not using it, you might see if there are some problems.","I think that probably they're going to be looking into how expensive it might be.","Like there's the problem. Such as?","Such as? I actually just like I suppose we have a 3.1, so you can definitely take a fraction of the franchise.","Dr. Glass That won't change the face.","And then you'll get like this sort of like this of you might say, okay, well then I should use like a non constant threat.","But then this original threat has to like look anonymous a number of times, finding a non constant number of threats."]}]}