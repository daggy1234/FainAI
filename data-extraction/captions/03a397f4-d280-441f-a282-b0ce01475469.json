{"data":[{"start_time":1,"end_time":180,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=0&isPrimary=false&absoluteTime=13357157101.021","captions":["I see actually, I. I feel like not.","Not. I just felt it.","I Christmas tree. I didn't think it was.","Oh, no. There's so much. No, no, not at all.","It's okay. I'll sit.","Down and watch it.","Yeah. So I watch it.","Oh. Yeah. Oh, yeah.","I'm sorry. I.","I feel like. An.","Right. You know, I'm really glad this.","That was. I got it.","Okay. Okay. Okay. Uh. Yes, ma'am.","I just got it down. Oh, my.","Gosh. I don't know what to tell you. Guys.","My time. I think it's awesome.","I mean, I. I like.","It's one of those. Anyway.","Yeah, I guess. I could go.","For coffee. I guess I.","Yeah. I'm just. Sorry.","I like that. Oh, yeah.","Yeah. Yeah. I.","I probably would have lost my legs.","Yes. Oh."]},{"start_time":222,"end_time":294,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=222&isPrimary=true&absoluteTime=13357157322.521","captions":["Yeah. Oh. And I couldn't forget.","And I really. You. Testing.","One. Two. Three. Testing. For the storm.","All right. Hello and welcome, everyone. Welcome to your favorite algorithms class.","And mine come side 330 for our 24th class together.","We'll be talking today a little bit about randomized algorithms and continuing their conversation on Thursday.","This is the beginning of our bonus reel.","That is the same material that is not going to be on the exam, but which I know you will all benefit from and I hope you're looking forward to.","Uh, however, I am going to wrap up a little bit today with the analysis of the, uh, k center clustering approximation factor that we began last time."]},{"start_time":360,"end_time":402,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=2&isPrimary=false&absoluteTime=13357157460.521","captions":["Uh, and nothing basically, that you haven't had a chance to practice in recitation and homework.","Uh, and last note for today is the UT. UT applications are still open at this link.","Please apply by April the 22nd. If you have enjoyed this course, or perhaps if you haven't enjoyed everything about this course,","but you have ideas for how to help someone else to enjoy this course.","You think algorithms are important? You'd like to be in a class on algorithms more and help other people to learn about algorithms.","Consider applying to be at UTA for comp Sci 330. Uh, if you have taken this class, you meet the prerequisites to apply.","I encourage you to consider doing that. Today."]},{"start_time":489,"end_time":540,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=489&isPrimary=true&absoluteTime=13357157589.521","captions":["This is one of many different styles of clustering problems where you want to group similar data","together into an overall a partition of your data into disjoint groups covering all of them.","There are many different ways you can set this problem up.","One way is with centroid clustering, where you represent a cluster by a point representing the center of that cluster,","and you assign all of your data points to the nearest center.","That's called uh, center clustering. Centroid clustering.","Uh, there are different objectives you could use to measure the quality of a particular clustering.","One of them is called the case center objective. It's essentially a worst case notion of quality.","It says well the quality is take a look at the point that is the farthest away from its closest center,"]},{"start_time":570,"end_time":690,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=570&isPrimary=true&absoluteTime=13357157670.521","captions":["Well, we looked at the following greedy approximation algorithm.","Initially, we chose an arbitrary one of the data points as our first center to represent our first cluster.","So suppose. Arbitrarily.","We had selected this point. Subsequently, we simply iterate up to the desired number of clusters.","Choosing as our next center the point which is furthest away from its closest center among those we have thus far selected.","That is to say, we choose as our next center precisely the data point which is currently determining the objective we would like to optimize.","It is in this sense that the algorithm is quite greedy, right? We say literally take the point that is currently causing my bad objective value.","Choose that as my next center, which of course sets the distance for that point to its nearest center to zero.","Okay. Uh, so, for example, if this was the first center we selected arbitrarily, the furthest away data point would perhaps be this one over here.","We would then select that as our second center. We would then iterate.","If we're gonna choose a third center then this is the nature of our picture where","now perhaps this point over here is the furthest away from its closest center,","and we would choose that. Next, we simply continue in this fashion until we've chosen K centers.","We close. Last time we were discussing how you could implement this algorithm to do it naively,","where you sort of recompute everything from scratch in that funny looking argmax of min line would lead to an O of k squared in algorithm.","But if you keep track of distances and update them a little bit more judiciously, you could easily get an O of k in algorithm k times.","In fact, what I did not prove to you last time is that this is actually an approximation algorithm,","and not just a goofy, greedy algorithm that does something extremely suboptimal.","Let me attempt to convince you of that now, in particular,"]},{"start_time":720,"end_time":900,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=4&isPrimary=false&absoluteTime=13357157820.521","captions":["How to argue this.","As in many of the cases, when we're discussing, uh, the analysis of an approximation algorithm and in particular its approximation factor.","We will begin by thinking about an optimal solution and trying to understand something of its structure,","and put that in relationship with what the heck our algorithm did.","That's usually the name of the game. So let's see star B, the optimal solution to a particular arbitrary input to this case into a clustering problem.","Okay. I'll just, uh, order these centers chosen by the optimal solution arbitrarily.","It chooses K of them. Uh, this will just be some notation for the k centers chosen by an optimal solution.","Let opt represent as usual the objective value of the optimal solution.","So the the cost of the set of centers which recall the cost of a set of centers is just the distance,","uh, from the point that is the farthest to its closest center in this solution.","Okay. Is that worst case notion of, of cost or of of quality?","By contrast, I'll denote by C a the solution of our greedy algorithm.","The algorithm solution. Question about the notation.","Okay. I'm going to divide my analysis into two cases,","which are structured around the relationship between the optimal solution and whatever the heck are greedy.","Algorithm did. Okay. The first case I will consider this is the one where, at a high level,","you should think what our algorithm did looks kind of like what the optimal solution did.","Okay. More precisely, if every cluster remember that our algorithm always chooses as its centers actual data points that need to be clustered, right?","That's how the algorithm works. The first case is if every cluster of the optimal solution includes a center from the algorithm.","Now, since the algorithm and the optimal solution both choose k clusters or k centers, that means in this case,","for every single cluster of the optimal solution, there is exactly one center from the algorithm in that cluster.","Meaning, if you look at it from a distributional perspective,","it looks kind of like the greedy algorithm did something similar to an optimal solution for every cluster.","And the optimal solution, we chose a center somewhere in that cluster.","Okay, that's one possibility. Let's examine that particular possibility first.","And I'm going to draw some pictures here. And I apologize if there's too much going on in the pictures.","First, we're going to try to consider an arbitrary input data point P.","We want to argue that in this case, the distance between P and its closest center from the algorithm from K cannot be too"]},{"start_time":1080,"end_time":1260,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=6&isPrimary=false&absoluteTime=13357158180.521","captions":["That's just a generic statement of the triangle inequality, right?","The distance going directly from P to the algorithm center.","Uh uh, for p in this cluster is at most the distance going indirectly from P to the center chosen by the optimal solution,","plus the distance from that center chosen by the optimal solution to whatever our algorithm chosen.","This cluster just applying the triangle inequality.","But recall copy, the center chosen by our algorithm is in this cluster.","It is a data point in this cluster, meaning that the optimal solution,","the quality of the optimal solution, is at least this distance from C star of P to C star of A.","The cost of a solution, remember, is the worst case over all data points to its nearest center, of which our algorithm chose as a data point.","And it's in this cluster an opt represented by C star of P.","So it counts. It's there in that maximum. It's one of the possibilities in that maximum.","So the cost of the optimal solution is at least this distance.","It could be more because maybe there's some other cluster we're not thinking about right now that's got an even worse distance.","But it's at least this. How then can I bound the quality of our algorithm solution which note I want to bound this","term the distance from an arbitrary point P to some center of the algorithm's choosing.","But we also know that since P, this arbitrary data point is also in the system of p cluster by the same upper lower bound.","The argument I gave here, the cost of an optimal solution is at least the distance from p to that particular center.","And I wrote down the distance the cost that our algorithm incurs on point P,","the distance from P to the center chosen by the algorithm as being the sum of these two terms.","Isn't that convenient?","I can conclude that the distance from this arbitrary point P to a center chosen by the algorithm is at most twice the cost of the optimal solution.","Because this property held for an arbitrary point P, I didn't make any assumptions about what p I was thinking about.","This holds for all of the p right? And thus in particular, it will hold for the maximum over all of the points p of this particular distance.","So we can conclude indeed that the cost of the algorithm is at most twice that of the cost of an optimal solution.","In case one or more case one was like for every, uh,","cluster of the optimal solution in our greedy algorithm happened to choose a center in that cluster.","Are there questions about case one's argument? In some sense, case two seems like the harder case."]},{"start_time":1440,"end_time":1605,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=8&isPrimary=false&absoluteTime=13357158540.521","captions":["And if you think about it for a second, as you continue to add centers in your greedy algorithm,","the cost of the solution only ever possibly decreases.","There's never a case in which adding an additional center could make a point further away from its closest center, right?","That would be impossible. The cost of the greedy algorithm is only possibly going down over additions of centers, and at this point,","the point at which we chose C2 of A, the cost of our greedy algorithm was exactly this distance, and it only possibly went down from there.","So in the end, it was at most of this distance and most of the distance between these two centers we selected.","That's great. That gives us some handle on the cost of the greedy algorithm solution.","How do we relate that again to the cost of the optimal solution, the triangle.","Right. We're going to use the triangle inequality from this picture. Again noting the fact that these are the same cluster a C star as before.","Applying the triangle inequality,","the distance between these two centers from the algorithm going directly is at most the distance going indirectly through in particular C star.","Okay, that's this first step. Each of these two terms is, uh, at most art by the same argument we had before, right?","C1 a was a data point, and it was a data point assigned in the cluster with center C star and an optimal solution.","So the cost of the optimal solution is at least that it's also at least that by the same argument we used in case one.","Adding these together, we again conclude that the cost of the greedy algorithm in case two is at most two times the optimal solution,","where the really crucial thing. Again, this is where we saw that relationship between the greedy choice of the algorithm","and the analysis was in how this C two of A must have been selected in particular.","Are there questions about case two of this analysis?","Or any lingering questions about, uh, approximation factors or analysis more generally."]},{"start_time":1620,"end_time":1641,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=9&isPrimary=false&absoluteTime=13357158720.521","captions":["Right. That's why we design approximation algorithms with randomized algorithms.","There are two flavors depending on what you are willing to give up.","Are you willing to give up deterministic in your, uh, runtime?","Where are you willing to give up deterministic incorrectness? Let me explain."]},{"start_time":1701,"end_time":1743,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=1701&isPrimary=true&absoluteTime=13357158801.521","captions":["values that are close to the minimum or close to the maximum of the elements that you're sorting.","What we did to address that issue way back in the day was to deploy randomization, okay.","Because we sort of said all we really need is to make sure that we don't have bad rounds of partition too often,","and it will be sufficient for our purposes to simply choose a random pivot,","and then to talk about what's the probability that we choose a really bad pivot over and over and over again?","Well, it's pretty low there. And doing that, we were able to characterize in several different senses the runtime of quicksort."]},{"start_time":1785,"end_time":1800,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=1785&isPrimary=true&absoluteTime=13357158885.521","captions":["That is one of two, uh, top level flavors, shall I say, uh, randomized algorithms, depending on where you prefer to gamble.","Where did we gamble that? We didn't gamble on correctness."]},{"start_time":1980,"end_time":2067,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=11&isPrimary=false&absoluteTime=13357159080.521","captions":["great, I can guarantee you that it's going to cost you more runtime.","Okay, so the runtime is going to be dependent on how much slack you're willing to give in the success probability.","We'll look at this example today, uh, and just uh, we won't look at this in this class for the sake of time.","But just to give you another interesting example, uh, the way that, uh, keys in cryptographic systems are often generated,","many of you have probably done something like SSH key gen or something like that to connect something to GitHub or something of that nature.","Um, one of the steps in the creation of large, uh, secure keys is typically to generate extremely large,","like on the order of thousands of bits, prime numbers and the typical approaches to doing that efficiently.","When you type SSH key in or something is actually to use an algorithm that just generates random numbers,","and then does a check to see if they're prime. And that check is not always correct.","So there are Monte Carlo style algorithms and that they just guarantee, uh, uh, numbers that are probably prime.","Are there questions about just this general reminder about randomized algorithms and this distinction of the flavors?","Well, let's dive into an example then, of the new flavor of a monte Carlo algorithm."]},{"start_time":2088,"end_time":2148,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=2088&isPrimary=true&absoluteTime=13357159188.521","captions":["but we talked about it in the context of s t flows and s t cuts.","In this problem, I give you a graph of vertices and edges, as well as a capacity function which tells you the capacity on each particular edge.","And if I ask you for a minimum, and I also give you a source and a target vertex and estimate t in particular,","if I ask you for an s t cut, I am asking you for a partition of the vertices.","That is to say, two sets, each of which has a subset of the vertices such that every vertex is in exactly one of the two sets, right?","So they jointly they cover all of the vertices, uh,","and in particular that separates the given s and T that separates the given source and target vertex.","That was the minimum s t cut problem that we looked at.","Now, you may remember, fondly or not fondly as maybe the case, uh, that you've got a homework problem,"]},{"start_time":2160,"end_time":2283,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=12&isPrimary=false&absoluteTime=13357159260.521","captions":["Here the graph is unweighted on incapacitated.","It's just an undirected graph with no weights.","And in this context, a cut is simply a partition of the vertices okay, into non-empty sets okay.","So you put at least one vertex in one set, at least one vertex in the other.","All the vertices should be assigned to one of the two sets, right? No vertex should be a multiple.","You just partition all the vertices into two sets, two disjoint sets, and the quality of such a a cut.","Such a partition is its size, where the size is simply the number of edges that cross the cut and edge is a cut edge if it crosses the cut,","that is to say, if it has exactly one endpoint in each of the two partitions.","So for example diagrammatically here,","this red line could represent one possible cut in the graph that puts these two vertices in one set and puts these three vertices in the other.","If you were to use this particular cut,","then this edge is a cut edge because it has one vertex in one side of the partition and another vertex in the other side of the partition.","This and this would also be cut edges to the size of this, uh, cut represented by the red line diagrammatically would be three.","By contrast, the size of this cut represented by the green line cut this vertex in one set and the other","four in a different set would only have size two corresponding to these two particular edges.","The diagram, of course, is just a diagram to visualize. In two dimensions, a cut is not actually a line you draw on a piece of paper.","The graph may not even be planar. Uh, instead, uh, this is the formal notion of the problem.","This is just a visual aid, just to be precise. Now, you were asked a question like this on homework eight and, uh, you of course,"]},{"start_time":2340,"end_time":2469,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=13&isPrimary=false&absoluteTime=13357159440.521","captions":["Okay, and you do some runtime analysis.","You think about the possible value of the max flow here,","and you would arrive at a runtime complexity of O of n squared M to solve precisely this problem.","So going in today we actually already have an algorithm for our problem of interest.","It's called the Ford Focus an algorithm. We can run it several times to answer this question.","And the runtime complexity would be O of n squared m. Right.","This is the kind of question about connectivity, this global min cut problem that you're interested in.","If you are interested in sort of the robustness or the resiliency of a network in an adversarial sense,","not just to, uh, particularly a breakdown of connection between a particular source and a particular target.","You want to know, given a network, whether it be, uh, a network corresponding to like, internet bandwidth traffic,","whether it be a real world road network or freight network or transit network for cargo ships,","whatever it might be, you're interested in how generally robust that network is.","That is to say, if I was to do like, how many edges would need to get disrupted before some connection would be broken, right?","That's the nature of this problem. We already know one way to solve it using for focusing are the questions about what the problem is.","Give it another three minutes. See you guys.","It's one. Mechanic back at you.","Amount of interest. That sacrifice.","Precisely. Yeah. So the question was, if I fix an S and T, I calculate the min cut in this kind of sense, right.","To set the capacities to one. And I look at the value of that.","Will that tell me, uh, in this reduction, like the, uh, number of edges you need to delete to separate s and T in particular?","And yes, that is exactly what that tells you. Okay, let's design a different approach to this."]},{"start_time":2520,"end_time":2700,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=14&isPrimary=false&absoluteTime=13357159620.521","captions":["but sometimes you could give me garbage.","You can also combine these two by the way, so you can have algorithms that guarantee that they are approximately correct with high probability.","Um, that has an interesting role in one of my favorite foundational, uh, theories of machine learning.","Uh, perhaps some of you familiar with PAC learning. Anybody? PAC learning.","It's not about Pacman.","So PAC learning is a famous theory that was developed to try to understand the complexity of learning different kinds of patterns in machine learning.","It stands for probably approximately correct learning.","If you want to combine both of these notions, you don't need to know anything about PAC learning for this class.","But, um, so you can combine these notions as well. Let's look at designing an algorithm using randomization.","Uh, that will be only probably correct but will be more efficient.","You'll have to bear with me.","It will take us some time to get to the version of the algorithm that will actually be more efficient than the n squared m we already have,","but we're going to get there. Okay, so so give me a little bit of time.","I only, however, need to introduce one basic new kind of operation on a graph.","And then the algorithm, the first variant of the algorithm itself will be relatively simple to describe the new operation.","It is called a contraction operation. Okay, here's what it looks like.","You contract an edge. So given an edge, let's say between some u and some v bolded in this diagram,","if we want to contract that edge, what it means is we're going to imagine taking those two vertices,","collapse them together into one vertex, leave all of the edges that were attached to either of those two vertices.","But if those two vertices themselves were connected to each other, don't draw like a self loop.","That's intuitively what's going on between these two pictures. And then I'll say the text up in a second.","So if we look at these two vertices okay let's look here. Look this node had an edge here.","This node had an edge here okay. This node had two edges here.","And this node had two edges. Uh over here uh we're going to combine these two nodes.","Right. And so after that, uh from this top left node here, we're going to have three edges corresponding to the boom boom boom.","The two vertices that we smushed together. Just imagine literally dragging them together and watching the lights follow.","Similarly, after we merged here, we have three edges to this top right vertex corresponding to this one, this one, and this one.","After we merge these two together, or contract these two vertices together.","Notice that there are edges between these two vertices, but we don't draw like self loops on this vertex after the contraction okay."]},{"start_time":2880,"end_time":3012,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=16&isPrimary=false&absoluteTime=13357159980.521","captions":["Contracting. If you operate in that fashion,","you will eventually result at a multi graph with two super nodes remaining corresponding to a partition of the vertices in your original graph.","In this particular sequence. Suppose we choose this edge first.","That means we're going to now contract this edge between these two vertices from the original graph.","Become a super note here, and perhaps we choose another edge.","We contract across it, we create another super node. So on and so forth.","At some point we may be choosing multiple super nodes to contract, but at each point in time,","one of the super nodes in the intermediate graph after this number of steps refers to a subset of the","vertices in the graph going back to the beginning and at the end when we just have two super nodes left.","Indeed, this uh, connotes, uh, it indicates exactly a partition of the vertices of the graph, which is the kind of thing we want to compute.","So there's a structural resemblance. And that's good. Our algorithm will basically be of the form.","Choose many edges, contract them until you get a partition until you get a cut right.","The name of the game is how should we choose what edges to contract?","And why is that a reasonable thing to do? First off, how many contractions do we need to perform?","Each contraction is going to reduce the number of vertices in your intermediary graph by one, right?","Because there were two nodes there before. Afterward we introduced one super node.","So the number goes from we. It decreases by one. Okay.","So you're going to need to do a linear number of these contraction operations in order to get some partition of the vertices to get down to some cut.","Each contraction operation we could do in linear time.","And so overall to get some cut by performing a sequence of contractions like this will take us quadratic time in the number of vertices.","So n squared. Here."]},{"start_time":3060,"end_time":3183,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=17&isPrimary=false&absoluteTime=13357160160.521","captions":["Choose an edge uniformly at random. Contracting.","Continue in that fashion until only two super nodes remain. Return that partition as your cut.","Hope for the best. This algorithm, one run of it is clearly quadratic time.","We just discussed that you could choose an edge uniformly at random.","Uh, efficiently. The crucial observation is that that yields a particular minimum cut.","I say particular because there could be multiple equivalent minimum cuts.","Um, but the kind of worst case for this algorithm is if there's only one minimum cut and you have to get exactly that one,","it yields a particular minimum cut if and only if we never contract any of the cut edges.","Think about this. If what we're left with at the end is a minimum cut is a partition corresponding to a minimum cut,","then all of these edges between the two super nodes left at the end are precisely the cut edges of that minimum cut.","We get that particular solution at the end only if we never contracted any of these edges at any of these previous steps.","If we contract a minimum a cut edge of the minimum cut at an intermediary step,","then two vertices which were in different sets in the optimal partition will be in the same set in the partition return.","Not an optimal solution, potentially.","So if you're interested in understanding how good of an algorithm this is, what you want to analyze is the probability of success.","What is the probability that the algorithm finds a min cut, meaning it never contracts a min cut edge?","Or alternatively, what's the probability of failure? The probability that indeed, the algorithm will contract a minimum cut edge at some step, where?","We'll talk more about that together in a minute. But first, let's chat with each other and maybe remind ourselves some things about probability."]},{"start_time":3240,"end_time":3420,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=18&isPrimary=false&absoluteTime=13357160340.521","captions":["Yeah. Yeah.","Yeah I can. Listen, I.","Just want to. Make.","Sure. You know how to tell.","A story. And.","I don't. Know.","If. That. Was right.","You might want. To watch.","Out for people who have. Almost three months now.","So probably. Because we are having a.","Yeah. I'm speechless.","They're. Just trying to figure.","Out. What's going.","So tell me, how are you going to.","Oh, yeah. Yeah. Let's go.","Let's go. I. Know you.","I know who you are. I do. If you can't. Do that.","You. Know I.","Just feel. Like.","I can. Still offer this.","You know what I'm saying?"]},{"start_time":3600,"end_time":3780,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=20&isPrimary=false&absoluteTime=13357160700.521","captions":["The correct answer here is the probability of choosing a ball on a red ball on one particular choice,","which is, uh, there a red balls in here total so k over m times the number you choose, which is at.","So it would be k times and over m, which is not one of the represented choices.","For the second question same prompt different question.","What's best represents the probability that all of the chosen balls are red and all of the chosen balls are red?","Very good. This is in b k over m to the nth power.","Where again, this is because the probability of choosing a red ball on one particular choice is k over m there k red balls out of it.","In total, you choose uniformly random and you have to make that success probability on every single one of n independent choices,","which is why you raise that to the nth power. Multiply.","You're looking at the probability that two independent random events both happen, right?","This has to happen and this has to happen. You multiply those together.","Uh, different question what that represents the probability that none of the chosen balls are red.","The correct answer is indeed one minus k over m to the end power.","This is the opposite, right?","So the probability that you do not choose a red ball is one minus the probability that you do choose a red ball which was k over m.","So the probability that you do not choose one is one minus k over m.","And then we have to do that all n times to satisfy this question.","So we raised that to the n power. The last question.","So the balls are edges in the input graph to the min cut problem.","And the red balls are the min cut edges for our problem of interest.","Which of the following characterizes the success probability of the contraction algorithm?","Is that the expected value from problem one. Is it the probability of all red from question two?","Is it the probability of none red from question three?","Or is it not any of those? The most common answer was the probability of none red from question three,","followed by the probability of all red from question two, followed by the expected value in question one.","And the correct answer is the seven of you who said it is none of the above, actually.","But I do believe the most popular answer is the probability of none red.","That's a very reasonable, uh, response, because indeed,","what we want from the contraction algorithm is that we never contract a red a min cut dash, right?"]},{"start_time":3873,"end_time":3960,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=5ec64957-d13d-4e59-8835-b14d0136692f&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=3873&isPrimary=true&absoluteTime=13357160973.521","captions":["Let's think then about what we can do to analyze the success probability.","Let me start by arguing to you that the probability that we contract a min cut edge, at least initially, is not very large.","Okay. Why is that? Suppose that there are k cut edges in a minimum.","Cut at the size of an optimal solution is k. Suppose that's that's the case.","Then I claim that there must be a reasonably large number larger with respect to k.","There must be a reasonably large number of edges in the graph. Why is that?","In particular, I want to say if there k if the size of the optimal solution of the minimum global cut is k,","then there must be at least k n over two edges in the graph.","This is an argument sort of by contradiction. Suppose this is not true.","Then by our favorite bird principle. Uh, if you like.","Then there has to be at least one vertex that would have degree less than k if this were not true, that is to say, has fewer than k incident edges.","But if there is a vertex with fewer than k incident edges with degree less than k, then the following cut would be better than a min cut of size k.","Take that one vertex by itself, in one partition, one set, and all the other vertices of the graph in the other partition.","That's a valid partition of the graph, a valid cut, and it would actually be better in that case, right?"]},{"start_time":4140,"end_time":4320,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=23&isPrimary=false&absoluteTime=13357161240.521","captions":["So we're going to have another one minus two over something term.","But rather than a one minus two over n it's going to be a one minus two over n minus one.","Okay. Times success probability on the resulting graph with one fewer vertex.","Continue unraveling your recurrence in that fashion. What do you get?","You get this long sequence of multiplied terms and you think, well, that's not helpful to me.","I wanted you to say something like, the success probability is like 2% or something.","Very important observation, though. If you look at it in this form, this sequence of multiplied terms looks not helpful and complicated.","But if you, uh, let's say combine these fractions, you start to see a pattern, this telescoping pattern sometimes called.","All I've done here is just combine these parentheses. Right. So I got one minus two over n I say well one is equal to n over n.","So this is n minus two over n. And I've just done that for all of the remaining terms okay.","I've just put them on their common denominator. Well if you do that and for building intuition it would really fit on the slide.","I might do like a few more terms than this. But if you do that you'll notice a very interesting pattern going on on the numerator up here n minus two,","n minus three, n minus four, n minus five and minus six and minus seven and minus eight.","On and on and on and on and on and on. These numbers are getting smaller, right?","N minus two is bigger than n minus three is bigger than n minus four.","These numbers are getting smaller by one at each step all the way down to three two and then finally one.","And the denominator is always two smaller than the numerator and is going in the same pattern,","and in minus one and minus two and minus three and minus four and minus five, so on and so forth.","Uh, and that stops down here at three. Almost all of the terms in this product cancel the n minus two.","And this numerator cancels with the n minus two. And this denominator this n minus three will cancel with an n minus three hidden in the ellipses.","This n minus four will cancel with an n minus four hidden in these ellipses.","So on and so forth. Okay, all the way down to the uh, this last term that will cancel will be this, this three here.","So all the numerators before that are going to cancel. And it is three here will cancel with this last denominator,","meaning that the blue factors are the only things you end up with just for the only things that are left after you cancel out,","all the common factors are in the denominator. This n times n minus one from the first two terms, and the two in the one from the last two terms.","Indeed, we can argue that the success probability of the simple random guessing algorithm is at least two over and n minus one,"]},{"start_time":4500,"end_time":4506,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=25&isPrimary=false&absoluteTime=13357161600.521","captions":["How many trials should you run? I'll finish the analysis next time, but I'll give you the answer today."]},{"start_time":4680,"end_time":1000000,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=d6c9390a-166d-482d-a473-b14d01364c1d&sessionPID=58f9a3b9-0b3c-4f69-8f06-b0ce01475462&number=26&isPrimary=false&absoluteTime=13357161780.521","captions":["Look, I know what this is about. I don't know if you.","Want to know why? It's a logarithm of one over epsilon. Uh, not particularly this topic, but I'm assuming the other one works for them.","I just can't seem to wrap my head around. And just like that.","There is just one person on the corner of the car.","Yeah, right. Right. You must.","Yeah. So then I got the chance to spend.","It's like it opens up and you sign up.","Yeah, yeah, my mom told her daddy like, a long distance.","Yeah, exactly. Um. And the proof and, uh, the proof of, like, Earth isolation.","You know. So if you think any of these.","What do I. You.","I just got. You."]}]}