{"data":[{"start_time":1,"end_time":81,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=0&isPrimary=false&absoluteTime=13357329901.041","captions":["To. You know, I was just telling.","You I should have no problem.","I mean. It is the capstone class.","Scary. You know, these are Emily.","Who? Are freshmen also working on our way.","To. Our project.","Oh, that's. Awesome.","I know you like silver.","So know. As.","Part of that, it's also kind of hard. I. It's kind of like my might not."]},{"start_time":159,"end_time":180,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=159&isPrimary=true&absoluteTime=13357330059.541","captions":["Before we do that some announcements. Today is your last due date for this course or your last assignment.","So congratulations to all of you. Um, especially those of you who were already finished with this, uh, and a soon to be congratulations.","For those of you who are nearly finished with this, that'll be our last assignment for the semester."]},{"start_time":255,"end_time":321,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=255&isPrimary=true&absoluteTime=13357330155.541","captions":["Here's what we'll do today. To begin, we'll finish up our analysis of, uh, cargoes of the kava Stein algorithm for the global min cut problem.","And then I'm going to spend the rest of the time today talking essentially about hashing.","We'll begin with reintroducing hash tables, a concept I know that you were already familiar with from 201 data structures and algorithms.","Uh, we'll go a little bit beyond the analysis that you may be familiar with to discuss exactly what are the kind of,","uh, perhaps more nuanced guarantees that are reasonable to expect about a hash table.","You will recall, uh, throughout the semester that I have sort of said, uh,","you should not expect a hash table to be able to obtain worst case, constant performance all of the time is not a reasonable expectation.","We'll discuss what are reasonable expectations and how they can be obtained by different kinds of hash functions in a little bit of detail today.","So that's our outline. Any questions or concerns about that?"]},{"start_time":327,"end_time":360,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=327&isPrimary=true&absoluteTime=13357330227.541","captions":["As a reminder here we're thinking about taking as input an undirected graph without any weights or capacities or anything like that.","And when we say a cut, we mean a partition of the vertices in the graph into two disjoint sets.","So every vertex should belong to one of the two sets. Uh, both of these sets should be non-empty and the size of a cut.","The value of a cut is the number of cut edges. That is to say, the number of edges with exactly one endpoint in each of the two partitions."]},{"start_time":405,"end_time":540,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=405&isPrimary=true&absoluteTime=13357330305.541","captions":["where the kind of guarantee that we gave was that the algorithm would have a deterministic runtime.","It was, in that sense, different than the much earlier randomized quicksort algorithm.","We considered, uh, where quicksort was always correct, but it had a runtime that was a random variable.","So we had to analyze its expected runtime. By contrast, uh, this algorithm using random contractions, uh, will have a deterministic runtime.","However, its correctness is probabilistic, so only some of the time this algorithm returned a correct solution.","In particular, uh, this first variant of the algorithm we looked at, uh, we argued, will return a uh,","particular global min cut if and only if it never contracts any of the cut edges of that minimum cut.","Okay. So we analyzed that probability last time and it was small okay.","In particular it looked like the probability of success probability,","the probability that we would output a a correct global mid-card was something like one over n where n is the number of vertices in the graph.","So if there's a large graph, a pretty small value, which sounded pretty bad.","But fortunately, if you have a randomized algorithm that outputs a correct answer with a certain probability and you'd like to boost that probability,","one standard thing that you can do is to simply rerun the algorithm several times,","using independent randomness across different runs in order to boost the success probability.","So if you run, uh, this partner min cut algorithm as it's written here,","meaning that, uh, you do capital n different times, this gets min cut algorithm.","Our question to analyze success is what is the probability that every single one of capital N trials.","We're overall just going to take the best of capital N trials against min cut.","What is the probability that every single one of those on a graph with little n nodes fails to find the optimal solution?"]},{"start_time":681,"end_time":720,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=681&isPrimary=true&absoluteTime=13357330581.541","captions":["This now comes down to algebra, right?","We know that our probability of success, uh, is, uh, sum over all for capital N runs is something like the expression shown here on the left.","And we want that, uh, to be. Excuse me. This is the failure probability.","We want that failure probability to be at most some epsilon.","Okay. What do we do. We solve for capital n okay.","So now we're just in an algebra game. In order to figure out how many trials we should do.","Uh, in order to solve that algebra game, the following identity is particularly useful and shows up in a lot of cases where you have,","uh, these kinds of, like expressions, uh, something plus minus something raised to a power."]},{"start_time":858,"end_time":900,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=858&isPrimary=true&absoluteTime=13357330758.541","captions":["We can put that back in to try to understand what the overall runtime of.","This randomized algorithm would be in order to guarantee a particular success probability,","a particular run of guess min cut, as we discussed last time, should take quadratic time.","Particular quadratic the number of vertices, not the number of edges o of n squared times of the graph.","And we concluded that we should run about at least about n squared log of one over epsilon of these trials of guess min cut.","That is to say, we should set this capital in here the number of times we're going to call guess min.","Cut to something about like this roughly in squared times log of one over epsilon.","Uh, in order to make the failure probability at most epsilon."]},{"start_time":1080,"end_time":1140,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=6&isPrimary=false&absoluteTime=13357330980.541","captions":["Um, in some cases. Are there questions about this now analysis so far of the first form of Carver's algorithm we've looked at?","Yes, we always look the problem right up with us.","But the question was, are we looking here at unweighted graphs of this problem?","We are looking at unweighted graphs here. You can adapt the ideas if you have weights, but I'm looking just at the unweighted set.","Okay. So then our challenge is can we improve this randomized algorithm to actually beat O of n squared m runtime,","which we know how to knew how to achieve, uh, using for Fulkerson.","For example, if we're giving up something with randomized algorithms like we're giving up,","uh, success with probability one, we should gain something in terms of runtime.","So how can we do that? In order to see how to improve the algorithm, it is helpful to consider where the algorithm tends to make mistakes."]},{"start_time":1260,"end_time":1296,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=7&isPrimary=false&absoluteTime=13357331160.541","captions":["The idea then for improving the algorithm is to put more attention in your trials on the final parts of the search,","the random interactions, then on the initial parts.","How can we, in a well structured algorithmic way, ensure that we are considering near the end, near the base case, if you will,","for a moment that we're considering many more possibilities there than at the beginning of the algorithm,","we'd sort of like to branch depending on the size of the input at this moment."]},{"start_time":1440,"end_time":1620,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=8&isPrimary=false&absoluteTime=13357331340.541","captions":["You should think about alpha as being a constant factor about two.","In fact, if you don't like the letter alpha because you hate Greek or I don't know, it just looks like a funny fish to you or whatever else.","Everywhere you see an alpha here, just ignore it and think too in your head and you'll be just fine.","But in principle you could change, uh, or tune that constant.","Think about it as something like to this says, okay,","take your current graph and run random contractions on it until you have about, uh, an over alpha nodes remaining.","So if alpha is to run random contractions until you have about half as many nodes left.","Then what do we do?","We make four recursive calls, each of them on that reduced super graph that we just constructed after mini, uh, random contractions.","Okay. And we just recurse on all of these.","Each of these should return a, uh, candidate min cut.","And our merge step is we just return the best of all four of those that we found.","One thing that's kind of written implicitly here, uh, is that there's a duplication step.","So the algorithm overall randomly contract the graph until only n over alpha nodes remain.","Uh, then here when you make these recursive calls like these are all on the same graph,","you need to actually duplicate this and run these as independent trials on the current state of the graph.","Okay. That's why I like to refer to it as duplicate and randomly conquer.","Are there questions about what this algorithm does? Yes.","I'm not saying it works like that. So brute force in this case.","Suppose that you have, uh, you go back to a picture.","Yeah. Suppose you like, uh, down here, for example, this is the state of the graph, and you want to find a global min cut in this super graph.","Try all possible partitions for example would be a trivial way to brute force.","Again, just to connect this back to the intuition. What is the purpose of doing this?","Because of this recursive branching. Think about it.","When you're getting down to very small super graph sizes,","they're actually going to be a ton of trials going to be growing exponentially because of this,","that are going to be happening on the last phases of the graph of the contraction.","Whereas early on, like in, for example, the very first, uh,","half of the graph contractions where you go from size little n to little n over two, for example, you just do that once."]},{"start_time":1680,"end_time":1800,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=1680&isPrimary=true&absoluteTime=13357331580.541","captions":["A single run of this better guess. I'm not going to prove, but let me just observe a lemma that for alpha about two.","That is to say, uh, every time you run a contraction before you make recursive calls here, uh, you reduce the size of the graph by about half.","Uh, the result after that sequence of contractions should still contain the minimum cut in G.","That is to say, you shouldn't have made a mistake with probability about a fourth.","Note that that's a constant precisely because we are reducing the size of the graph in one of these,","like alpha equals two by like a constant fraction, not like a raw number.","So in a given contraction step, let's say you use an alpha about two.","You reduce the size of a half.","And one of those uh, you should not have messed up, not have contracted a mid cut edge with probability about one fourth.","It's not great. But hey, a constant fractions a lot better than one over n or one over n square.","If p of n is, then the success probability on a graph with little and nodes,","and we're using again alpha about two, then the probability of success obeys the following kind of recurrence.","It's one fourth. Why do we get a one fourth there. That's because okay.","If we mess up in this, uh, in the very first contraction step that we do, then we're I mean, we're toast, right?","So we only have a chance if we didn't mess up in the contraction step here.","And that happens with probability about one fourth. I'm telling you that's the factor.","One fourth. And then what's going on with the rest of this."]},{"start_time":1923,"end_time":1980,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=1923&isPrimary=true&absoluteTime=13357331823.541","captions":["Because of course a given run,","a better guess could potentially be more expensive than a single run of the very simple random guessing algorithm we started with.","So let's analyze the runtime running this contraction algorithm.","Uh, looks something like this. Okay. Uh, remember, if a given contraction, you can do an O of n time,","and then it's just a question of how many contractions do you do, which is not necessarily also n here.","Uh, but this quantity is certainly o of n squared.","Okay. Imagine you choose again. You should think of alpha as being something like a constant like two roughly.","So if alpha is two then this whole thing is something like n over two.","And this is something like that. Right.","So you should think about this, one of these contraction steps happening here, for example, as taking about open squared time.","Now for this duplicate and randomly conquer algorithm, its run time not success probability."]},{"start_time":2118,"end_time":2160,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=2118&isPrimary=true&absoluteTime=13357332018.541","captions":["In particular if we have our overall Carter Stein minimum cut algorithm.","Okay, uh, we have our better guess algorithm we've been analyzing.","And then over here you'll note this looks exactly like the algorithm we looked at earlier.","Run many trials. Take the best of all of the trials.","Except, uh, now replace this naive guess.","Min cut with bitterness. So run many trials.","A better guess. How many trials should you need?","Well, if. Remember, we analyzed our success probability now as being something like o of one over log n.","So this is then the failure probability we have to fail on. All capital and trials in order to fail over all."]},{"start_time":2340,"end_time":2520,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=13&isPrimary=false&absoluteTime=13357332240.541","captions":["Uh, you might wonder what's going on there.","So sometimes algorithms people will say that a randomized algorithm is correct with high probability if its failure probability is at most one over n,","where n is the size of the input uh, meaning for high probability bounds.","Usually people demand that the failure probability diminish with the size of the input is something that you'll see.","I've chosen to give you the more general form of the statement here.","Obviously, if you want your failure probability, uh uh epsilon to be one over n,","then if you substitute one over n here, you would get the same thing of n squared loss.","But in principle you could specify whatever failure probability y. You can run this algorithm.","In fact, the only change it makes in running the algorithm when you specify a failure probability is to tell you how big should you set capital N?","How many random trials do you want to run? Which again, this part, the random trials here is embarrassingly parallel.","It's trivial to distribute these to as many course as you have. Right.","So I think that concludes what I wanted to say about the Kirstein algorithm and computing very efficiently.","Global min cuts with randomized algorithms. Uh, questions with thoughts about this.","Yes. So is that accounting for um again or would that add another.","Uh, so the question is is this accounting for running in parallel.","So no, every all the analysis we've done has been for uh, for just serial execution or something like that.","Um, my point is, if you're interested in optimizing in, uh, in a parallel implementation, shaving this factor is trivial to do.","Uh, I just do random trials on each of your course that you have available.","So if you have if you want a failure probability one over epsilon and you have like log of one over epsilon course,","then you're not going to need this necessarily if you're distributed in parallel.","The n squared is sort of fundamental. Right. Because even a given quarter is going to have to take n squared just to read the input again.","Yes. Uh, so I just this algorithm, there's the original I, I on the last one, uh, we're used to think like an s.","Yeah. So, so the question is just a reminder about, um, the original algorithm that you considered in your homework using Ford.","Fulkerson. Uh, that runs and runs a Ford Fulkerson on a, uh, unit capacity graph, each of which takes, uh, at most o of n m time.","So the overall runtime of that was O of n squared m, where m is the number of edges in the graph.","For a dense graph, the gap is the largest. So for a dense graph, M can be as large as n squared,","meaning that that algorithm using for Fulkerson would have been O of n to the fourth on a dense graph,","uh, as opposed to here we get n squared plus log factors."]},{"start_time":2586,"end_time":2610,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=2586&isPrimary=true&absoluteTime=13357332486.541","captions":["Uh, reintroducing a data structure that you all know and love and use very frequently.","And let's try to understand now that we've introduced some of these concepts in randomized analysis.","Some of the nuances of how you should actually expect performance to look for these data structures, these hash tables,","as well as what kind of functions are necessary to guarantee such performance, especially in the worst case."]},{"start_time":2700,"end_time":2826,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=15&isPrimary=false&absoluteTime=13357332600.541","captions":["No, we can support the same kind of thing. We can represent a set or associative matrix, like a lookup table, using a binary search tree as well.","And you may recall from way back at the very beginning this semester,","I told you that the guarantees for a self-balancing binary search tree implementation are much simpler, like it's log in period.","Worst case always for a self-balancing binary search tree.","Whereas I said that the story is much more complicated for a hash table implementation.","So let's consider why that is. The basic idea is to store your hash table as a table, basically an array.","I'll call it an array t of length m where we're going to store an elements.","Okay. When you add an element to your set, rather than just adding it to say,","the next available position like you would if we were just using a list to represent our set.","Instead, we use a hash function to have a consistent way of indexing into the table, both when we are adding an element and searching for an element.","Okay. Now, uh, that hash function you think about taking an element you might like to store in the set as input.","You calculate the value of the hash function.","Uh, that will be some kind of an integer that tells you then the index at which you will store the given element in the table.","If you can calculate the hash value in constant time, you can go and look up and put in the correct position in the array in constant time.","You can add in constant time. You should also be able to search in constant time by just calculating the hash of the element you're searching for,","and looking up the appropriate index in your array. All is good and well in the universe,","and this is the degree of understanding that is typically offered in things like standard library documentations of many languages is just,","oh, uh, our hash table data structures, constant time add and search.","But that can't be quite true. It can't be quite true because of the reality of collisions in your data structure."]},{"start_time":2880,"end_time":2997,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=16&isPrimary=false&absoluteTime=13357332780.541","captions":["and you add the element to that list. Simple enough.","When you want to search, you also calculate the hash of the element.","Go to that position in the table, and then you search in a linear fashion over the list stored there to see if it contains the other.","Assuming that you can compute your hash function value in constant time, you're adding search operations.","Now take something like linear time with respect to the size of the list at the position to which this element would hash.","If I want to search for the element x, then I've got to calculate the hash and find that corresponding list.","That's always going to take me at least constant time. Um,","but then I also have to consider that I may need to search over the list that I'm storing at that position of all of the elements that collided there,","which could be more than 1 or 2 things in principle.","The question then in hash table design, action design generally is how should you design a couple of things?","On the one hand, the hash function h. What should you use for a hash function?","How should you compute these indices? And on the other hand, the table size.","How big of a hash table should you use in order to keep this quantity small and thus run times, uh, efficient, preferably near constant time?","I'll sometimes refer to this L of x as the load at, uh, x position in the table, the number of elements that have collided there.","Questions conceptually about so far. I'm hoping if this sounds very familiar to you, um, but by way of introduction about what I'm referring to.","All right. First up, naive hashing, which is often how, uh, one is sort of first introduced to calculating a hash function."]},{"start_time":3060,"end_time":3240,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=17&isPrimary=false&absoluteTime=13357332960.541","captions":["That is to say the remainder dividing by s.","Okay, in many programing languages, instead of mod, you write the percent right for the remainder when dividing by m y.","Because if we have an array with m positions indexed 01234 all the way up to m minus one,","then after I divide by m, the remainder must be a value in the set zero,","one, two, three all the way up to m minus one, so it appropriately maps onto the set of valid indices in the table.","And sometimes this is called the division method.","And for a hash function, I don't call it that because it's naive. So I call it the naive hash function.","Here, however, is one way of analyzing the performance of even a naive hash function to achieve the kind of guarantees that one expects,","which is to say something like I expect good performance on average, whatever that means.","Constant performance on average in some sense. Here's one way to characterize what on average could possibly mean.","It could mean with respect to your data.","That is to say, for example, if the n elements that you are storing the n unique elements of Z that you are storing in your hash table are,","let's say, all sampled, uh, uniformly and independently at random from the set of integers.","Let's say you're storing totally random integers.","Then it's easy to see that even this naive hash function you have the expected load because each integer is a random integer.","Okay. And in this, uh, just spreads those around in the hash table uniformly, uh, that the probability that a random integer gets hash,","any particular position is just one over m, and you're hashing n things in total.","So the expected load at a particular position in the hash table is just an over n under an assumption about your data,","which is always a small assumption to make. Sometimes I'll refer to the load factor alpha, uh, referring to this particular quantity,","the ratio of the number of elements to the size of the hash table.","In this case, the expected time where this expectation is over the randomness in your data over.","You're assuming there's something random about your data distribution. The expected runtime of, say,","search after hashing all of these elements is O of one plus alpha the immediate","because you know one to compute the hash and find the appropriate list.","And then alpha is the expected size of that list, for example,","the implication being that in the average case with random data, you expect constant time operations to search,"]},{"start_time":3420,"end_time":3426,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=19&isPrimary=false&absoluteTime=13357333320.541","captions":["Um, instead we will use, uh, a random hash function."]},{"start_time":3600,"end_time":3660,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=20&isPrimary=false&absoluteTime=13357333500.541","captions":["That's a very bad hash family because it turns out you create your hash table.","You sample one of these uniformly at random. That means you sample some value from this uniformly at random.","Let's say you get seven. You're going to now use h sub seven as your hash function.","What does h sub seven do? It maps everything to position seven, which means with probability 1 or 100%.","Or to think of it that way, this is a terrible hash function.","You will get a terrible hash function and terrible performance with probability one sampling from this family.","Despite the fact that it is uniform, the probability with respect to the random draw is indeed uniform over the positions in the table.","What this tells us then is uniformity, while intuitive, is not sufficient.","It's not sufficient to guarantee good performance. We want a stronger property, and we.","Think about a good hash function or a good hash family."]},{"start_time":3780,"end_time":3882,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=21&isPrimary=false&absoluteTime=13357333680.541","captions":["That is to say that collide with x. I think the universal guarantee tells us that for any Y, this quantity is, uh, the probability that this is a one.","Is it most one over M where m is the size of the table?","I think certainly x is going to go there.","So we definitely have some uh have x there. Uh, and then we sum over all of the remaining elements,","the probability that those hashed to the same position as x is at most one over M for each of them by the universal property.","So the expected load looks like one plus and minus one over m at a position where something is being stored,","implying that if you have a universal hash function,","then the expected search time on average over your elements and expectation over the random draw of your hash function is of one plus alpha,","where alpha is the load factor. The same guarantee that we had earlier,","but needing to make assumptions about our data rather than doing something in our algorithm to ensure this would hold true regardless of the data.","Okay. Again, the implication is that if you use a hash table of size comparable to the number of elements that you want to store,","and you use a universal hash family and you draw from it,","then you can expect that average case searches will have constant time performance, which is a pretty nice property to have."]},{"start_time":3960,"end_time":4140,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=22&isPrimary=false&absoluteTime=13357333860.541","captions":["You all are allowed to talk if you want.","To. And let me just tell you about that.","All right. The difference between the two cities.","First and foremost, it's. Exactly how it is.","And at this point, I. How do you understand the rules?","Yeah. So. It's crazy for.","Us to ask for help. Yeah, I think it's a lot more reasonable.","Yeah. Oh nine.","Nine. Nine. Tonight.","Sorry for your loss.","Yeah. Or is there something? Yeah. It's fine.","I have to leave. But right now, it's playing in your.","Shirts and shorts.","Yeah. Yeah, I was confused when I invited.","You here? You can talk, I think.","Yeah, yeah, I think I can, I guess.","I can say. Yeah, yeah.","Yeah. Thank you. Yeah.","I mean, I want to have someone, you know, I mean, you know, I don't, I don't.","Here. Elizabeth.","I'm. Sorry, ma'am. I'm sorry.","I'm. Sorry, I can't.","Actually. You. Know it's."]},{"start_time":4254,"end_time":4320,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=712288c8-af36-496b-8178-b14f01367f13&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=4254&isPrimary=true&absoluteTime=13357334154.541","captions":["Uh, so all of these questions refer to storing and distinct elements in a hash table size roughly,","and drawing a hash function uniformly at random from some family.","They're all true or false. First up, a uniform hash family guarantees constant expected runtime search on average over elements.","That is false. A uniform hash family does not guarantee that.","It actually doesn't guarantee that even for random data.","So the bad example of a uniform hash family I just discussed would not give you constant high performance, even for random data.","It's that bad family. Second question A universal hash family guarantees constant time.","Expected run, constant expected runtime search on average over the elements.","That is true. That is precisely the kind of guarantee that you can guess it expected, uh,","over the randomness of the draw runtime for an average element is constant."]},{"start_time":4500,"end_time":4500,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=25&isPrimary=false&absoluteTime=13357334400.541","captions":[]},{"start_time":4680,"end_time":1000000,"image":"https://duke.hosted.panopto.com/Panopto/Pages/Viewer/Thumb.aspx?eventTargetPID=a55d5629-ee9d-428e-8aff-b14f013659f2&sessionPID=2871b7a6-0ba7-4f1e-b3c7-b0ce0147547b&number=26&isPrimary=false&absoluteTime=13357334580.541","captions":["You. I think I will tell people that I actually got the job.","I was always selfish. In other words, I.","Was on the verge of what I am.","I knew that if. I.","Was having done it. If you had left. He was, I could.","Things you can do to support this work.","There are. Plenty of opportunities to offer.","He took the shelters unaccompanied. I don't understand why.","So the is. Uh.","Oh, he should have. Just.","Put more."]}]}